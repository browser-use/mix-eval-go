[
  {
    "confirmed_task": "Read webpage https://www.instagram.com/douglasjaveda/ and follow the prompt: Analyze the Instagram profile for 'Douglas J Aveda Institute'. Extract information on the type of content posted (e.g., student work, behind-the-scenes, tutorials), frequency of posts, user engagement (likes, comments), use of hashtags, and any collaborations with influencers. Summarize their Instagram marketing strategy.",
    "task_id": "2118230",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Toronto Regional Real Estate Board latest market analysis",
    "task_id": "91371",
    "category": "Search"
  },
  {
    "confirmed_task": "\nStep 1: Open web browser and vist amazon.com\nStep 2: Search for plazzo in women category\nStep 3: Among the plazzo's select the one with highest rating\nStep 4: Open the highest rating plazzo and extract the reviews complete list\nStep 5: print the logs on the prompt\n",
    "task_id": "446054",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Visit the website: https://www.omahasteaks.com/.\nYour goal is to navigate to the checkout page of this website. The checkout page is where payment details are to be entered to buy something sold on this website.\nOnce you're at the checkout page and ready to pay, stop. Do not enter any actual payment information.\n\nNavigation instructions:\n1. Typically, to get to checkout you will need to add at least one item to the cart.\n2. Prefer taking the most direct route to checkout.\n3. If necessary, use the provided credentials to enter any personal information required to proceed. Make up plausible information if needed.\n\nHandle these common scenarios:\nPopups/Interruptions:\n    - Close newsletter subscription popups\n    - Dismiss cookie consent notices\n    - Minimize or close chat bot windows\n    - Handle \"Don't leave\" exit-intent popups\n   \nAuthentication:\n    - If guest checkout is available, prefer that option\n    - If account creation is required, use provided credentials / make up plausible information\n    - For social login prompts, prefer email/password registration\n\nProduct Selection:\n    - If size/color selection is required, choose the first available option\n    - If items show as \"out of stock,\" select an alternative\n    - Handle \"items in your cart are selling fast\" notices\n   \nPrice/Promotion Handling:\n    - Dismiss promotional overlay popups\n    - If promo code field exists, leave blank unless specified\n    - Handle \"spend more to get free shipping\" prompts by proceeding anyway\n   \nTechnical Issues:\n    - If page loading takes >30 seconds, refresh the page\n    - If redirected to error page, go back and try alternate path\n    - If region/location popup appears, select: United States\n\nStop when you reach the page where credit card/payment details are to be entered. Do not enter any actual payment information.\nReport any blocking issues that prevent reaching the checkout page.\n",
    "task_id": "757446",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Visit https://lectuepub3.com/ and analyze whether the website contains phishing or malicious content. Identify any suspicious links, fake login portals, or other indicators of phishing. Return a verdict as 'Allowed' if the website is safe, or 'Not Allowed' if it is malicious.",
    "task_id": "270711",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "search for regisetered agents in california and extracf the registered agent name and links on each page and exclude the add sponsored ,youtube videos , people also search for and other irrelevant links only focus on the registered agent list avoid all the other links only focus on the search results obtained and visit upto 10 pages",
    "task_id": "24748",
    "category": "Search Results Extracting"
  },
  {
    "confirmed_task": "scrape tender information from https://www.eib.org/en/projects/pipelines/index.htm and extract the following information for each tender: title, reference number, submission deadline, estimated budget, brief description of the scope, eligibility criteria, type of procedure, and dedicated URL. If any piece of the requested information is unavailable, return 'N/A' for that field. If the page might not have loaded all tenders yet, first try pagination, then try waiting a few seconds and retry until you are certain whether tenders are available. Return the results as a JSON array of objects.",
    "task_id": "1219357",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Goal: Find recent Chrome browser engine vulnerabilities related to UXSS and cross-origin access disclosed in 2024\n\nCandidate URLs: \n- https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=chrome+uxss+2024\n- https://msrc.microsoft.com/update-guide/vulnerability\n- https://www.zerodayinitiative.com/blog\n- https://blog.google/threat-analysis-group/",
    "task_id": "1071505",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Intune compatibility requirements for Dell Latitude and OptiPlex models",
    "task_id": "91640",
    "category": "Web Research"
  },
  {
    "confirmed_task": "search zillow.com for 1 or 2 bedroom rental apartments in Berkeley, California that that have no stairs, within 2 blocks of public transportation, within 4 blocks of berkeley bowl supermarket or monterey market supermarket. use google maps to help with these queries.",
    "task_id": "37757",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Goal: Find specific technical details of body-parser CVE-2024-45590 vulnerability mechanism\nExpected output: Detailed explanation of the vulnerability mechanism, how attackers could exploit it, and code examples if available\n\nCandidate URLs: \n- https://github.com/expressjs/body-parser/blob/master/SECURITY.md\n- https://github.com/expressjs/body-parser/releases/tag/1.20.3\n- https://www.suse.com/security/cve/CVE-2024-45590.html",
    "task_id": "1201234",
    "category": "Web Research"
  },
  {
    "confirmed_task": "On mergr.com, navigate to the transactions page and extract all transaction details from page 1. Return the data as a list of dictionaries with transaction details.",
    "task_id": "342762",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Chrome Speculation Rules API CVE 2024",
    "task_id": "1068300",
    "category": "Search"
  },
  {
    "confirmed_task": "\n            Find the website for Local Court Records (Henrico County).\n            Search for the company 'A Plus Roofing' with context: {\"location\": \"2907 Hungary Spring Rd, Henrico VA 23228\"} using the method: Search the Henrico County court records for any civil or criminal cases involving 'A Plus Roofing' as a plaintiff or defendant. This may reveal legal disputes or financial issues..\n            Extract the following attributes: Plaintiff, Defendant (A Plus Roofing), Case Type, Judgements, Liens.\n            Export all found information in structured JSON format.\n            You must include the URL you extracted the data from in the results.\n            Do not try to login to any website. You do not have credentials for any login.  \n            If at any point you get blocked by cloudflare, attempt to bypass it.  If you are unable to do so STOP.",
    "task_id": "1237178",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Go to https://eprocure.gov.in/eprocure/app, search for all the past tenders award winners and make a excel",
    "task_id": "259349",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Fetch me lowest price for 'Apple iPhone 14 Pro Max'",
    "task_id": "1373007",
    "category": "Price Scraping"
  },
  {
    "confirmed_task": "Fetch the the name, company, phone, email, and website of lawyers at https://irela.org/Lawyer-Directory for the first 150 lawyers. ",
    "task_id": "1081387",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Find me the best price for iPhone 16 pro max 256 GB in Bahrain",
    "task_id": "319822",
    "category": "Price Scraping"
  },
  {
    "confirmed_task": "Search for two-compartment stainless steel kitchen sinks on Amazon, narrow down the list to those with FREE shipping included, and find the product with the lowest price.",
    "task_id": "2050850",
    "category": "Price Scraping"
  },
  {
    "confirmed_task": "Go to amazon.com and search for Alpha-GPC. For each product on the results page, report the product name, ASIN ( from the value of \"data-dib-asin\" ), price, quantity / packs,  shipping time,  price per count,  highlights count ( ex: span with the text 5 Highlights), rating (4/5 stars), and review count ( near rating),  supports prime shipping status ( if you find  \"a-icon-prime\" )",
    "task_id": "1012582",
    "category": "Search Results Extracting"
  },
  {
    "confirmed_task": "Read webpage https://www.facebook.com/ads/library/?active_status=all&ad_type=all&country=US&q=posture%20corrector&sort_data[direction]=desc&sort_data[mode]=relevancy_monthly_grouped and follow the prompt: Go to the Facebook Ad Library, search for ads related to 'posture corrector' in the United States, and report on the number of active ads and the general ad angles being used.",
    "task_id": "2275751",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://www.dji.com/it and follow the prompt: Analizza la homepage di DJI Italia per confronto competitor. Semplicemente carica la pagina e analizza:\n\n1. TITOLO E META:\n   - Title tag della homepage\n   - Structure generale del sito\n   - Focus keyword principali visibili\n\n2. CONTENUTO HOMEPAGE:\n   - Prodotti principali evidenziati\n   - Tipologia di contenuto presentato\n   - Call-to-action utilizzate\n\n3. NAVIGAZIONE:\n   - Struttura menu principale\n   - Categorizzazione prodotti\n   - Link interni strategici\n\n4. DIFFERENZE CON DRONEBASE:\n   - Approccio brand vs rivenditore\n   - Focus su innovation vs vendita\n   - Target consumer vs professional\n\nNon interagire con elementi, solo osservazione e analisi del contenuto visibile.",
    "task_id": "1788829",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Find information about Stromal Therapeutics AG pipeline and stage of development",
    "task_id": "486215",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Detail the payment structures and included benefits in DataRobot's enterprise solutions",
    "task_id": "1284368",
    "category": "Web Research"
  },
  {
    "confirmed_task": "\nGo to:\nhttps://stake.com/sports/valorant/all\n\n1. Wait until the page is fully loaded and all Valorant leagues are visible, memorize the leagues.\n2. Click on each league to reveal upcoming matches (exclude live matches).\n3. From the page, extract the raw match details under the key \"match_details\". Each match detail includes:\n   - \"date\": e.g. \"March 2, 2025\"\n   - \"time\": e.g. \"7:00 PM\"\n   - \"teams\": an array with two elements (first is the home team, second is the away team)\n   - \"betting_options\": an array; find the object where \"type\" equals \"Match Winner\" and note its \"options\", e.g. { \"G2 Esports\": \"1.50\", \"T1 Esports\": \"2.40\" }\n4. Transform the raw data into exactly the following JSON format:\n{\n  \"games\": [\n    {\n      \"match_date\": \"March 2, 2025 7:00 PM\",\n      \"home_team_name\": \"G2 Esports\",\n      \"away_team_name\": \"T1 Esports\",\n      \"home_odds\": 1.50,\n      \"away_odds\": 2.40\n    },\n    ...\n  ]\n}\nNotes:\n- \"match_date\" is a concatenation of \"date\" and \"time\" separated by a space.\n- \"home_team_name\" is the first element in \"teams\", \"away_team_name\" is the second.\n- Convert the odds from strings to floats.\n- Do not include any keys other than those specified.\n- If no upcoming matches are found, output {\"games\": []}.\nImportant: Output only the JSON and nothing else.\n",
    "task_id": "872717",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://hailuoai.video/ and follow the prompt: Navigate to the MiniMax Hailuo AI website and find comprehensive pricing information. Look for:\n1. Subscription/pricing plans page\n2. API pricing information \n3. Credits system details\n4. Per-second video generation costs\n5. Model versions and pricing differences\n6. Enterprise pricing options\n7. Fast generation pricing\n\nPlease click on relevant navigation links like \"Subscribe\", \"API Access\", \"Pricing\", or similar to find detailed pricing information. Extract all pricing details you find.",
    "task_id": "1842739",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://inflact.com/instagram-downloader/ and follow the prompt: Go to the Inflact Instagram Downloader and use it to download all posts from the URL 'https://www.instagram.com/supersnake/?hl=en'. I need the post URL, image/video URL, caption, and hashtags. Save the output to a file named 'inflact_results.json'.",
    "task_id": "2226746",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "You are tasked with collecting property data from the Miami-Dade Property Appraiser's database. Please follow these steps carefully:\n\nSTEP 1: DATA COLLECTION For the subject property located at 791 NW 20 ST, Miami, please collect the following information:\n\nProperty Information:\n\n- Folio Number\n- Property Address\n- Legal Description\n- Primary Owner Name\n- Mailing Address\n- Property Type\n- Year Built\n- Units (if applicable)\n\nAssessment Information:\n\n- Current Year Value\n- Previous Year Value\n- Land Value\n- Building Value\n- Market Value\n- Assessed Value\n- Exemptions (if any)\n\nSales Information:\n\n- Most Recent Sale Date\n- Most Recent Sale Price\n- Previous Sale Date(s)\n- Previous Sale Price(s)\n- Sale Type/Qualification\n\nLand Information:\n\n- Lot Size/Land Area\n- Zoning Code\n- Land Use\n\nBuilding Information:\n\n- Total Living Area\n- Adjusted Area\n- Number of Bedrooms\n- Number of Bathrooms\n- Building Type\n- Construction Type\n- Floor Count\n- Effective Year Built\n\nAdditional Information:\n\n- Special Features\n- Extra Features\n- Utility Information\n\nSTEP 2: IDENTIFY NEIGHBOR Select one neighboring property that shares a property line with the subject property.\n\nSTEP 3: REPEAT DATA COLLECTION Collect the same information outlined above for the selected neighboring property.\n\nSTEP 4: DATA ORGANIZATION For each property collected, organize the data according to the following format: [Provide specific column mapping here that matches your spreadsheet headers A through AD]\n\nSTEP 5: CONFIRMATION Provide a summary of:\n\n- Total properties processed (should be 2)\n- Addresses of properties processed\n- Confirmation that all required fields were found and documented\n\nOUTPUT FORMAT: Present the collected data in a structured format that can be easily transferred to a spreadsheet, with clear labeling of each data point and which property it belongs to.\n\nIMPORTANT NOTES:\n\n- If any data field is not available, mark it as 'N/A'\n- Maintain consistency in data formatting (dates, numbers, etc.)\n- Flag any discrepancies or unusual data points\n- Do not make assumptions about missing data\"",
    "task_id": "68754",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Navigate to the U-Haul website, input the origin zip code 01420 and destination zip code 20743, and extract the pricing, availability, and detailed specifications (capacity, dimensions, door opening, deck height, length, and features) for all available truck sizes. Start at: https://www.uhaul.com/",
    "task_id": "1570984",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://www.sec.gov/Archives/edgar/data/1318605/000162828025003063/0001628280-25-003063-index.htm and follow the prompt: Navigate to the Tesla 10-K filing: https://www.sec.gov/Archives/edgar/data/1318605/000162828025003063/0001628280-25-003063-index.htm. Click on the link or button to access the 'Interactive Data' or 'XBRL data'. Within the interactive data viewer, navigate to the 'Consolidated Balance Sheets'. Extract the full table(s) for all presented years (typically two years: current and prior). Ensure the extraction includes key line items like Total Assets, Total Liabilities, and Total Stockholders' Equity.",
    "task_id": "1664550",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Versa Networks vs Aruba EdgeConnect feature comparison table",
    "task_id": "1302424",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Read webpage https://duckduckgo.com/ and follow the prompt: Search for '5G telesurgery market size report' and provide a summary of the key findings, including market size, growth rate, and key players.",
    "task_id": "2252269",
    "category": "Search"
  },
  {
    "confirmed_task": "Read webpage https://cloud.google.com/text-to-speech/pricing and follow the prompt: Go to the URL and extract the detailed pricing information for the Text-to-Speech API. I need the costs per million characters for different voice types like Standard, WaveNet, Neural2, and any other tiers. Please present the pricing in a clear, structured format.",
    "task_id": "2228307",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://www.greeencode.com and follow the prompt: Analyze this software agency website to understand: 1) What services they offer, 2) Their target market and industries, 3) Their value proposition, 4) Case studies or portfolio examples, 5) Their pricing model if visible, 6) Their team size and expertise areas. Extract all relevant information that would help identify ideal prospects for their services.",
    "task_id": "2225648",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Canada February 2025 economic calendar official releases and details",
    "task_id": "121347",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Goal: Get comprehensive details about recent vulnerabilities in the \"ws\" library and understand security best practices when implementing WebSockets for browser communication.\nBackground motivation: I need to get more detailed information about specific vulnerabilities in the \"ws\" WebSocket library, especially the most recent ones like CVE-2024-11045, CVE-2024-37890, and CVE-2024-28251, as well as understanding the security implications when using WebSockets for browser communication.\nExpected output format: Detailed descriptions of the recent vulnerabilities in the \"ws\" WebSocket library, including exploitation methods, impact, and affected versions. Also information about general WebSocket security best practices for browser communication.\n\nCandidate URLs: \n- https://nvd.nist.gov/vuln/detail/CVE-2024-11045\n- https://nvd.nist.gov/vuln/detail/CVE-2024-37890\n- https://nvd.nist.gov/vuln/detail/CVE-2024-28251\n- https://github.com/websockets/ws/security/advisories/GHSA-9p6p-326h-77c5\n- https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Application_Security_Testing/11-Client_Side_Testing/10-Testing_WebSockets",
    "task_id": "1798795",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Goal: Get specific details about CVE-2021-22881 and CVE-2024-41801 related to Rails HostAuthorization IPv6 hostname validation\n\nCandidate URLs: \n- https://nvd.nist.gov/vuln/detail/CVE-2021-22881\n- https://nvd.nist.gov/vuln/detail/CVE-2024-41801\n- https://github.com/rails/rails/pull/51018\n- https://github.com/rails/rails/commit/ffc5df4cdafb6dddac70b4e543458983c89ba121",
    "task_id": "1092722",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Your task is to extract all relevant documentation from GitHub Copilot Documentation efficiently while ensuring structured and meaningful information gathering. The goal is to collect and organize all documentation pages without unnecessary delays while still maintaining an approach that mimics human understanding of content relationships.\n\nSteps:\nNavigate to the Documentation Homepage: Open https://docs.github.com/en/copilot.\nParallel Processing for Efficiency:\nOpen multiple pages simultaneously (e.g., 3-5 at a time).\nExtract content as quickly as possible without losing structure.\nExplore and Extract Content from All Sections:\nStart with Overview & Getting Started.\nMove to Code Completions, Copilot Chat, Customization & API Integrations.\nCover Security, Enterprise Features, and any advanced topics.\nKey Information to Capture:\nPage titles, full text content, structured documentation.\nPreserve code snippets, examples, lists, tables, and links.\nIdentify and categorize related topics.\nEfficient Navigation & Data Collection:\nSkip redundant elements (ads, headers, footers, sidebars).\nUse structured extraction (e.g., JSON, CSV, Markdown).\nEnsure no duplicate pages are processed.",
    "task_id": "93046",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Goal: Search for prAIrie-dog application documentation and source code repositories, particularly focusing on LangSmith integration implementation\nBackground motivation: Looking for the prAIrie-dog application which appears to be an AI-related application that integrates with LangSmith. I need to find official repositories, documentation, or technical specifications that detail how LangSmith is integrated into this application for security analysis purposes.\nExpected output format: Direct links to repositories, documentation pages, architecture diagrams, configuration files, and implementation details showing LangSmith integration\n\nCandidate URLs: \n- https://github.com\n- https://docs.langsmith.com\n- https://python.langchain.com",
    "task_id": "2341493",
    "category": "Search"
  },
  {
    "confirmed_task": "goto google search for ceo linkedin and copy first 2 result  name and their email and  provide me the result",
    "task_id": "163717",
    "category": "Search Results Extracting"
  },
  {
    "confirmed_task": "Indonesia drone delivery pilot programs regulation 2023",
    "task_id": "1435178",
    "category": "Web Research"
  },
  {
    "confirmed_task": "1. search on Google - how to apply French Visa in Ireland and go to page. 2. In the page, follow steps to reach to \"calendar\" page. 3. check and find any available appointment date nad time slot",
    "task_id": "248538",
    "category": "Search"
  },
  {
    "confirmed_task": "Find the latest financial performance of Wayfair, including revenue, profit margin, and growth trends.",
    "task_id": "1028041",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Search Google for 'best practices for music retailers expanding into food sales' and 'successful case studies of non-food retailers starting food lines'. Visit the top 3 relevant results for each search, extract key recommendations, risks, operational hurdles, and effective strategies for digital retailers adding food sales. Summarize specific actions, partnership models, or trends that apply. Return a synthesized overview, then recommend a strategy for Famous Records.",
    "task_id": "1801366",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Goal: Find detailed information about Google Cloud's data processing agreements, regional data handling, and specific policies for AI services like Vertex AI and Gemini\nBackground motivation: Need comprehensive documentation about data processing locations, cross-border transfers, and specific policies governing AI services data handling across different regions\nExpected output format: Legal agreements, data processing addendums, and technical documentation about regional data handling for Google Cloud AI services\n\nCandidate URLs: \n- https://cloud.google.com/terms/data-processing-addendum\n- https://cloud.google.com/vertex-ai/docs/data-governance\n- https://ai.google/responsibility/responsible-ai-practices/",
    "task_id": "2329850",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Goal: Find best practices and security recommendations for using jsonwebtoken's verify method\nExpected output: Specific security best practices for using the verify method, including proper configuration of the 'algorithms' option and other security-critical parameters.\n\nCandidate URLs: \n- https://cheatsheetseries.owasp.org/cheatsheets/JSON_Web_Token_Cheat_Sheet.html\n- https://auth0.com/blog/a-look-at-the-latest-draft-for-jwt-bcp/\n- https://github.com/auth0/node-jsonwebtoken/wiki/Security-Best-Practices",
    "task_id": "1190684",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Go to url: https://www.wanhai.com/views/Main.xhtml and search BL no. 027E664477\n        then click the B/L Data link, extract the B/L detail information\n        then repeat the process for each row in the Ctnr No. column:\n        1. click the link, extract all the container movement list in the new page\n        2. return to B/L detail information page, click the next row, extract all the container movement list in the new page\n        output the B/L detail information and all container detail information as json, remove all escape characters\n        ",
    "task_id": "185981",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Open the webpage https://www.adb.org/work-with-us and retrieve a list of the first 3 currently open tenders with their details including title, reference number, submission deadline, estimated budget, scope, eligibility criteria, and type of procedure.",
    "task_id": "887205",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "search for existing trademark registrations for 'AgentWeb' in the USPTO or other trademark databases.",
    "task_id": "161186",
    "category": "Search"
  },
  {
    "confirmed_task": "Read webpage https://www.wordstream.com/keywords and follow the prompt: Navigate to the WordStream free keyword tool (wordstream.com/keywords). I need to find the top 25 blanket-related search terms for South Africa, along with their search volume and CPC. Please perform searches for the following keywords and record the results: 'blanket', 'electric blanket', 'fleece blanket', 'mink blanket', 'weighted blanket', 'aranda blankets', 'pure pleasure blankets'. For each keyword, please provide the top 5-10 related keywords with their search volume and CPC in South Africa.",
    "task_id": "2309290",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://www.biggerpockets.com/forums/899/topics/1083016-best-property-management-software and follow the prompt: Navigate directly to the forum thread at 'https://www.biggerpockets.com/forums/899/topics/1083016-best-property-management-software' and extract all user comments and discussions about property management software. Focus on the pros and cons of different software options, challenges faced, and desired features. Capture specific quotes and examples.",
    "task_id": "2068140",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://www.immoweb.be/en/search/house-and-apartment/for-rent/gent/9000 and follow the prompt: Search for rental properties in Ghent 9000 area, focusing on townhouses and larger properties (120-140m2). Extract details about properties near Gravensteen or in the historic center, including rental prices, property sizes, features, and exact locations. Pay special attention to properties with terraces, outdoor space, or historic views.",
    "task_id": "2099475",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Consult Hugging Face's official documentation to learn how to implement margin-based loss for their PPO training pipeline.",
    "task_id": "2155793",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Read webpage https://www.flipkart.com and follow the prompt: Continue collecting products from Flipkart in the following categories. I need approximately 40 products from:\n\n1. Books & Media (books, stationery) - 15 products\n2. Sports & Fitness (equipment, clothing, accessories) - 15 products  \n3. Beauty & Personal Care (cosmetics, skincare, grooming) - 10 products\n\nNavigate to these categories and collect products with:\n- Product URL (working link)\n- Product name/description\n- Actual price (MRP)\n- Deal price (current selling price)  \n- Discount percentage\n\nFocus on products with good discounts and clear pricing. Target around 40 products total from these three categories.",
    "task_id": "2110707",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Navigate to https://minnodillc.com and perform a comprehensive SEO analysis based on the homepage. Extract:\n1. Page title\n2. Meta description\n3. Number of H1, H2, and H3 tags\n4. Number of images with and without alt text\n5. Page load time (estimate in seconds)\n6. Presence of keywords in title, meta description, and headings\n7. Internal and external link counts\nReturn the data in JSON format only:\n{{\n    \"page_title\": \"str\",\n    \"meta_description\": \"str\",\n    \"headings\": {\"h1\": int, \"h2\": int, \"h3\": int},\n    \"images\": {\"with_alt\": int, \"without_alt\": int},\n    \"load_time\": \"str\",\n    \"keywords\": {\"title\": [\"str\"], \"meta\": [\"str\"], \"headings\": [\"str\"]},\n    \"links\": {\"internal\": int, \"external\": int}\n}}",
    "task_id": "910053",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\n                1. Navigate to https://www.genesisenergy.co.nz/join.\n                2. Select For Home.\n                3. Click the Continue button.\n                4. Enter address '7 Thornycroft Avenue, Epuni' into the address field and select the matching option from the dropdown options that appear.\n                5. Click the Continue button.\n                6. Select Electricity Only.\n                7. Click the Continue button.\n                8. Ensure the page has text 'Which plan works for you?'.\n                9. Return the extracted pricing details in JSON format with fields for:\n                - Plan name\n                - Daily charge\n                - kWh rate\n                - Any additional fees or discounts.\n                ",
    "task_id": "1201195",
    "category": "Price Scraping"
  },
  {
    "confirmed_task": "\n\nYou are a specialized web analysis agent with expertise in financial categorization systems, particularly Merchant Category Codes (MCCs). Your task is to analyze https://idfy.com and determine the most appropriate MCC based on the business's activities, products, or services.\n\n## Process:\n\n1. Visit the provided website URL\n2. Analyze the website content thoroughly\n3. Extract key business information\n4. Determine the most likely MCC code and category\n5. Document your reasoning\n6. Return structured results\n\n## Website Analysis Guidelines:\n\n- Focus on the homepage, about page, product/service descriptions, and any pages that describe the business's main activities\n- Look for explicit statements about the type of business\n- Analyze the products or services offered\n- Check for industry-specific terminology or regulatory information\n- Note any secondary business activities that might influence categorization\n\n## Information to Extract:\n\n- Business name (official name as displayed on the website)\n- Billing name (if different from business name)\n- Full URLs for the following pages:\n  * About Us\n  * Terms & Conditions\n  * Privacy Policy\n- Shipping details (methods, fees, timeframes)\n- Return and refund policies\n\n## MCC Determination:\n\n- Identify the 4-digit MCC code that best represents the primary business activity\n- Include the official category name associated with that MCC\n- List 2-3 alternative MCCs that could potentially apply (closest matches)\n- Provide clear reasoning for your determination\n- Assign a confidence score (1-100) representing your certainty in the MCC selection\n\n## Response Format:\n\nYour analysis must be comprehensive but structured according to the specified schema. Include all available information, but mark fields as null when information cannot be found.\n\nRemember:\n- Be thorough in your analysis\n- Consider the primary business activity as the main determinant for MCC\n- Provide specific reasoning that references website content\n- Be precise about confidence levels\n",
    "task_id": "1065230",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "ASML 2023 annual report revenue breakdown by product line and region",
    "task_id": "86041",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Access the URL https://www.contractsfinder.service.gov.uk/Search/Results and extract the first 20 tenders with their details: title, reference number, submission deadline, estimated budget, brief description, procedure type, and dedicated URL. Use pagination if necessary to reach the target number of tenders.",
    "task_id": "1465541",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Navigate to Dice.com and follow these steps carefully:\n\n1. In the location textbox enter 'Tallahassee, FL'\n2. Click the Search Jobs button\n3. Once results load, apply these filters:\n   - Posted Date: Last 3 Days\n   - Job Type: On-Site\n\n4. After the filters are applied:\n   - Scroll through the page to ensure all jobs are loaded\n   - Extract jobs in batches of 5-10 at a time\n   - For each batch, format them into valid JSON before moving to the next batch\n   - Combine all batches into a final complete JSON response\n\nCOPY AND USE THIS EXACT TEMPLATE:\n\n{\n  \"jobs\": [\n    {\n      \"Title\": \"PASTE THE EXACT JOB TITLE HERE\",\n      \"Description\": \"PASTE THE FULL JOB PREVIEW TEXT HERE\",\n      \"URL\": \"PASTE THE FULL JOB URL HERE\",\n      \"Location\": \"Tallahassee, Florida, USA\",\n      \"PublicationDate\": \"PASTE THE POSTED TIME HERE (e.g. 2 hours ago)\",\n      \"Company\": \"PASTE THE EXACT COMPANY NAME HERE\",\n      \"JobType\": \"PASTE THE EXACT JOB TYPE HERE\",\n      \"Source\": \"Dice.com\",\n      \"Deadline\": null\n    }\n  ]\n}\n\nEXTRACTION PROCEDURE:\n1. Start with a clean JSON object containing a jobs array\n2. Process 5-10 jobs at a time\n3. Validate each batch is properly formatted before continuing\n4. Ensure the final response has ALL jobs wrapped in a single jobs array\n5. Make sure every field uses proper double quotes\n6. Verify the JSON structure is complete before submitting\n\nFIELD REQUIREMENTS:\n1. Use EXACT field names shown above (case-sensitive)\n2. Include ALL nine fields for EVERY job\n3. Source must be exactly 'Dice.com'\n4. Deadline must be exactly null (no quotes)\n5. Use the complete job preview text for Description\n6. Use the full URL for each job listing\n7. Keep original job type and company name exactly as shown\n8. Format dates exactly as shown on the site (X hours/days ago)\n\nJSON FORMATTING RULES:\n1. Must start with { and end with }\n2. Use double quotes for all strings\n3. No trailing commas after last item\n4. Add commas between jobs in the array\n5. No extra text or markdown code blocks\n6. No single quotes anywhere\n7. Proper nesting of brackets and braces\n",
    "task_id": "959157",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Goal: Find details about the most recent critical Next.js vulnerability (Authorization Bypass in Next.js Middleware)\n\nCandidate URLs: \n- https://github.com/vercel/next.js/security/advisories/GHSA-9vp7-r9jw-79hj",
    "task_id": "1093228",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Find clinical trials for KRAS G12D inhibitors from Amgen and Mirati on clinicaltrials.gov",
    "task_id": "705643",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "What is the typical price range for Brother inkjet printers at Electronic Express?",
    "task_id": "2078884",
    "category": "Price Scraping"
  },
  {
    "confirmed_task": "Official resource links and documentation for FDIC OCC Federal Reserve NCUA CFPB compliance guidelines and mandates",
    "task_id": "451937",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Federal Reserve rules and guidelines for US bank regulatory compliance core systems site:federalreserve.gov",
    "task_id": "68296",
    "category": "Search"
  },
  {
    "confirmed_task": "AKAM RNG GLOB stock analyst ratings news price targets",
    "task_id": "785349",
    "category": "Search"
  },
  {
    "confirmed_task": "Get me the official social media (facebook, instagram, twitter) followers/likes/views for the Forza Horizon 5 game including views, likes, comments, shares, and date of publish.",
    "task_id": "1476019",
    "category": "Social Media Interactions"
  },
  {
    "confirmed_task": "Go to proxyserver.tech and perform a comprehensive SEO audit focusing on the keyword 'mobile proxies mexico'. Check the following: 1) If the site is optimized for this keyword (title, headers, content, meta tags) 2) Site loading speed using Google PageSpeed Insights 3) Mobile responsiveness 4) On-page SEO elements 5) Site structure and navigation 6) Content quality and keyword usage. Provide detailed recommendations for improvement.",
    "task_id": "1391181",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Conducting a survey for Family Superstore, could you show the top-priced product in the anti-aging serum shelves?",
    "task_id": "688004",
    "category": "Price Scraping"
  },
  {
    "confirmed_task": "Read webpage https://acem.org.au/ and follow the prompt: Go to the ACEM website (acem.org.au) and search for clinical guidelines or position statements on the evaluation of chest pain, acute coronary syndrome, or troponin measurement. Extract the relevant recommendations.",
    "task_id": "2275411",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "site:broward.deedauction.net assessed value for properties in the most recent auctions",
    "task_id": "415465",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://www.minimaxi.com/ and follow the prompt: Analyze the MiniMax website comprehensively. I need to understand:\n1. Overall layout and structure of the homepage\n2. Navigation menu and header structure\n3. Main content sections and their arrangement\n4. Design elements: color scheme, typography, visual style\n5. Interactive features and animations\n6. Footer content and structure\n7. Call-to-action buttons and their placement\n8. Any unique design elements or special features\n9. Mobile responsiveness indicators\n10. Overall user experience flow\n\nPlease capture detailed information about each section, the visual hierarchy, and how content is organized. Take screenshots if helpful and note any interactive elements.",
    "task_id": "1833859",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\n            Your task is to extract fashion product information from an e-commerce website.\n\n            1. Visit https://themanatomy.com/\n            2. Navigate to the shop or product listing page if not already there\n            3. Identify and extract information for up to 20 fashion products\n            4. For each product, collect:\n               - Product name (required)\n               - Price as a numeric value without currency symbols (if available)\n               - Brief description (if available)\n               - Color information (if available)\n               - Full URL to the product image (if available)\n               - Full URL to the product page (required)\n               - Category or type of product (if available)\n\n            5. Organize the data as a structured JSON array of product objects\n            6. Focus on clothing/fashion items if this is a general e-commerce site\n            7. Make sure each product has at least a name and product_url\n\n            Return ONLY the JSON array containing the extracted product information.\n            ",
    "task_id": "967725",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://ppubs.uspto.gov/pubwebapp/static/pages/landing.html and follow the prompt: For each of the following USPTO patent queries:\n1. Navigate to the USPTO Patent Public Search Advanced Search: https://ppubs.uspto.gov/pubwebapp/static/pages/landing.html then click 'Advanced Search'.\n2. Enter the specific patent number query (e.g., `\"2020051500\".pn.`).\n3. Execute the search. There should ideally be only one result.\n4. Click on the result link to view the patent details.\n5. Scroll down or navigate within the document viewer to find the section titled 'Claims' (usually preceded by an `<h2>` tag).\n6. Extract the *entire* text content under the 'Claims' heading until the next major section heading (like 'Description'). Ensure all numbered claims are included.\n7. If the patent is found but the 'Claims' section cannot be located, report 'Claims section not found'.\n8. If the search yields no results or an error occurs, report 'Patent not found or search error'.\n9. Report the results as a list, pairing each original Patent Number (e.g., US-2020051500-A1) with its extracted claims text or the specific error/status.\n\nQueries/Patent Numbers:\n- Query: `\"2020051500\".pn.` (for US-2020051500-A1)\n- Query: `\"2020174255\".pn.` (for US-2020174255-A1)\n- Query: `\"10959334\".pn.` (for US-10959334-B2)\n- Query: `\"11284428\".pn.` (for US-11284428-B2)\n- Query: `\"2022365637\".pn.` (for US-2022365637-A1)",
    "task_id": "1434249",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "ONLY go to https://drs.faa.gov/browse/ADFRAWD/doctypeDetails. Select Make as 'The Boeing Company'. Wait until Model options are loaded. Select Model as '777'. Wait until Series options are loaded. Select Series as '300'. Set Citation Publish Date from 01/01/2005 to 31/12/2024. Click Apply Filters. Extract Airworthiness Directives fields like AD Number, Subject Heading, Subject, Status, Effective Date, Office of Primary Responsibility, Docket Number, Citation, Citation Publish Date, etc. Save results into structured CSV format.",
    "task_id": "1486500",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "https://www.birdeye.so/, Search this address GYTd9XbZTfwicCV28LGkwiDF4DgpXTTAi2UeCajfpump , then go to holders section, and get a list of tokens hold by the second largest holder of the mentioned Address",
    "task_id": "1300023",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://emeralddrift.myshopify.com/ and follow the prompt: Crawl the website https://emeralddrift.myshopify.com/ and identify any potential technical SEO issues. Pay attention to the following: canonical tags, robots.txt, sitemap.xml, structured data, and any broken links or error messages. Also, assess the mobile-friendliness of the site.",
    "task_id": "2304432",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Goto flipkart.com and search for sunscreen. Then give me the top 3 results. Extract name of the brand, original price and net price. Give the answer in a structured format.",
    "task_id": "1154550",
    "category": "Search Results Extracting"
  },
  {
    "confirmed_task": "scrape the webpage for tender information: https://www.renewableenergyworld.com/energy-business/energy-finance/ and extract all tenders with their details, including title, reference number, submission deadline, value, description, requirements, evaluation criteria, procedure type, and dedicated URL. Handle pagination if necessary.",
    "task_id": "1625592",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\n    You are a helpful assistant that validates if an issue detected by an upstream system is a real issue on the website or not.\n    You will be given an issue and a website url.\n    You will need to check if the issue is a real issue on the website or not.\n    You will need to use both the text content and visual screenshots of the page to validate the issue.\n    If two products are compared, or two page previews (example: product previews in a category page) are compared and show different details, click on both to go in depth into comparing, just like a human would.\n    Basically you're doing an in-depth analysis of the error, and you're trying to find out if the issue is a real issue on the website or not.\n    You will need to return a detailed markdown report of your evaluation, and if you couldn't evaluate if the issue is a real issue or not, you should also return a reason why you couldn't evaluate it.\n    Every time, whatever happens, you should return a report at the end.\n\n    Here is the issue:\n    {\n  \"title\": \"Resolve Conflicting Canon Extender RF 2x Lens Compatibility Claims with Canon RF 70-200mm Lenses on PDP\",\n  \"severity\": \"high\",\n  \"status\": \"open\",\n  \"page_type\": null,\n  \"regions\": [\n    \"US\"\n  ],\n  \"platforms\": [\n    \"desktop\",\n    \"mobile\"\n  ],\n  \"description\": \"The PDP for the Canon Extender RF 2x presents conflicting lens-compatibility information: the official compatibility list and Q&A say the extender does NOT work with RF 70-200 mm lenses, yet multiple customer reviews claim successful use with those lenses. This contradiction can mislead shoppers and should be clarified or corrected on the page.\",\n  \"shortlink_url\": \"https://www.bhphotovideo.com/c/product/1573777-REG/canon_rf_extender_2x.html/specs\",\n  \"shortlink_title\": \"RF 2x Extender Compatibility\",\n  \"issue_rows\": [\n    {\n      \"row_type\": \"text\",\n      \"title\": null,\n      \"content\": \"Official compatibility list (Screenshot 6) omits RF 70-200 mm lenses, while a customer review (Screenshot 9) states the extender \\\"Works perfectly with my R5 and 70-200 mm z lens.\\\" These two authoritative areas of the PDP directly contradict each other and create shopper confusion.\"\n    }\n  ]\n}\n\n    Here is the url to check on:\n    https://www.bhphotovideo.com/c/product/1573777-REG/canon_rf_extender_2x.html/specs\n    ",
    "task_id": "2357186",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\n                    URL to visit: https://sales.cabincloseoutstore.com/app/0/cruise/0/search_cruises_quick.html?clear=all&search[search_type]=cruise_only&search[sailing_date]=02%2F08%2F2026&search[duration]=7&search[ship_id]=1390080&passengers[1][1][type]=ADT&passengers[1][1][residency_airport]=BDL&passengers[1][2][type]=ADT&passengers[1][2][residency_airport]=BDL\n\n                    Task details:\n                    1. Go to the provided URL above.\n                    2. Look for and select the cabin category: Oceanview\n                    3. Click on the \"View Rates\" button of the selected category.\n                    4. Select the first option for all.\n                    5. Choose the cabin and click on the \"Select\" button.\n                    6. Navigate to the passenger details/options page and retrieve the final price.\n                ",
    "task_id": "885451",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Goal: Find information about CVRF and OpenVAS vulnerability reporting formats\nBackground motivation: Need to gather details about the Common Vulnerability Reporting Framework (CVRF) which is now CSAF, and OpenVAS/Greenbone vulnerability reporting formats\nExpected output format: Technical details about CVRF/CSAF standard and OpenVAS vulnerability reporting formats, including JSON schema structures and examples\n\nCandidate URLs: \n- https://docs.oasis-open.org/csaf/csaf/v2.0/csaf-v2.0.html\n- https://github.com/greenbone/openvas\n- https://www.greenbone.net/en/product-comparison/\n- https://community.greenbone.net/t/about-greenbone-community-feed-gcf/1224",
    "task_id": "1736753",
    "category": "Web Research"
  },
  {
    "confirmed_task": "\n        1. Navigate to https://key.com to find relevant documents.\n        2. Answer the question: Does the company provide a Gramm-Leach-Bliley Act (GLBA) privacy notice explaining how nonpublic personal information is collected, used, and shared, and consumers' right to opt out?.\n        3. consider the following hints:\n        Extract the status of the company's compliance with the Gramm-Leach-Bliley Act (GLBA) regarding financial privacy notices. Specifically, determine if the company provides a GLBA-compliant privacy notice that explains how nonpublic personal information (NPI) is collected, used, and shared, and includes consumers' rights to opt out of data sharing with nonaffiliated third parties. Consider relevant GLBA requirements when making your assessment.\n        4. pick the answer from the following list: Compliant Notice/Partial/Not Provided/Not Applicable.\n        5. Save your response in the following JSON format with key 'signal_11':\n        ```json\n        {\n            \"question_id\": \"11\",\n            \"question\": \"Does the company provide a Gramm-Leach-Bliley Act (GLBA) privacy notice explaining how nonpublic personal information is collected, used, and shared, and consumers' right to opt out?\",\n            \"answer\": \"<your answer>\",\n            \"rationale\": \"<reason for the chosen answer>\",\n            \"reference_urls\": \"<urls of documents contains info to answer the question>\",\n        }\n        ```\n    ",
    "task_id": "1889096",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Navigate to Google News:\nOpen https://news.google.com/home?hl=en-IN&gl=IN&ceid=IN:en.\n\nSearch for Narendra Modi News:\nIn the search bar, enter \"Narendra Modi\" and execute the search.\n\nSelect Top 5 News Articles:\nFrom the search results, identify and choose the top 5 news articles related to Narendra Modi. Open then in new tabs.\n\nExtract Article Details:\nFor each of the selected articles, perform the following:\n\nClick the headline to open the respective news publication website.\nExtract the full headline.\nRetrieve the article URL.\nScrape the complete text of the article.\n\nOutput the Results:\nProvide the information for each article, including:\n\nThe headline\nThe URL\nThe complete article text",
    "task_id": "941592",
    "category": "Search Results Extracting"
  },
  {
    "confirmed_task": "Goal: Find detailed information about CVE-2023-51651 affecting AWS SDK for PHP\nExpected output: Comprehensive information about the vulnerability details, the fix implemented, and any related security advisories for CVE-2023-51651 affecting AWS SDK for PHP\n\nCandidate URLs: \n- https://nvd.nist.gov/vuln/detail/CVE-2023-51651\n- https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-51651\n- https://github.com/aws/aws-sdk-php\n- https://aws.amazon.com/security/security-bulletins/",
    "task_id": "1209626",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Read webpage https://www.wordtracker.com/ and follow the prompt: Use the Wordtracker free keyword tool to research keywords for \"G-Code Viewer\", \"Poker Analyzer\", and \"Chess Notation Keyboard\". Extract all keyword suggestions with any available metrics including search volume and competition data.",
    "task_id": "2121476",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://www.escardio.org/Guidelines and follow the prompt: Navigate to the European Society of Cardiology (ESC) website (escardio.org). Go to the 'Guidelines' section and search for guidelines related to 'intracerebral hemorrhage' or 'stroke'. Extract any relevant recommendations about antithrombotic therapy.",
    "task_id": "2274972",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\n            Context:\n            You are a compliance agent. Your task is to check if entities have been sanctioned by the US government.\n            You will be given a list of entities. For each entity, you will need to check if it has been sanctioned.\n            Unless otherwise specified, use the following website to check for sanctions: https://sanctionssearch.ofac.treas.gov/.\n\n            Task:\n            Check if the following entities are sanctioned: [Alphabet,VTB Capital,X]. If there are multiple search results for an entity,\n            identify if any entities in the results match the entity you are checking. \n            In your done text explanation, provide a valid json array with the following schema. Make sure there is exactly one entry per entity.\n            \n            [\n                {\n                    \"search_entity\": str,\n                    \"is_sanctioned\": bool,\n                    \"explanation\": str\n                },\n                ...\n            ]\n        \n         ",
    "task_id": "927731",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\nYou are an expert auditor for CRO checklists. \nThese were the instructions given to find if an item of a CRO checklist is good or not:\n```\n\n        You are an expert auditor for CRO checklists. \n        You are given a task to check Material and care information for the overall goal of checking Product Information, in details you are checking precisely if the following issue is present on the page: Are material composition and care instructions clearly listed?\n            These are the exact steps to follow to check the issue: \nNavigate to the https://fr.caudalie.com\n- Go to a product detail page\n- Locate material information in the product details\n- Verify that material percentages are listed for relevant products\n- Check if care instructions are clearly provided\n- Verify that washing/cleaning symbols are used where appropriate\n- Check if there are any special care warnings highlighted\n\n            At every step if there's a modal and it's not what you're evaluating, close it.\n            In the output, 'before' should represent the current state of the issue if there is one, and 'after' should represent the state of the issue if it's fixed, with a solution for the issue.\n            \n```\n\nYou are given a task to double check if the issue is indeed present on the page: \nis_issue=True description='Material composition and care instructions are listed, but material percentages are not detailed. Care instructions are present but without washing symbols.' details_report_long=\"The product 'Gouttes Solaires Autobronzantes' specifies that it is made from 99% natural ingredients and offers a list of exclusions like sulfates, soap, and alcohol. While this provides a general guideline about the composition, specific percentages for each ingredient are not provided, which could be important for users with allergies or sensitivities. The care instructions advise users on how to properly mix and apply the product, but lack universal washing symbols which can be crucial for non-expressive instructions or for users who rely on such symbols due to language barriers. Additionally, no special warning is provided except for instructing not to use alone and to wash hands after application, which may suffice depending on typical use scenarios.\" title='Incomplete Material and Care Information' relevant_fields=['description'] before_after=BeforeAfter(before='99% natural ingredients listed; lacks specific material percentages and care symbols.', after='Detailed material percentages included; universal washing symbols and special care warnings added.')\n\nAnd return the result of the double check, enhanced or modified if necessary.\n",
    "task_id": "867913",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Goal: Obtain specific details about the vulnerabilities including how they work, exploitation methods, and remediation steps\nBackground motivation: Need to gather comprehensive details about the vulnerabilities in TI WooCommerce Wishlist plugin from the Patchstack database\nExpected output format: Detailed technical descriptions with exact citations from the source\n\nCandidate URLs: \n- https://patchstack.com/database/wordpress/plugin/ti-woocommerce-wishlist/vulnerability/wordpress-ti-woocommerce-wishlist-2-9-2-arbitrary-file-upload-vulnerability\n- https://patchstack.com/database/wordpress/plugin/ti-woocommerce-wishlist/vulnerability/wordpress-ti-woocommerce-wishlist-plugin-2-9-2-cross-site-scripting-xss-vulnerability",
    "task_id": "1792712",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://www.loopnet.com and follow the prompt: Search for vacant retail and warehouse spaces over 50,000 sq ft in Charlotte, North Carolina. Navigate to the search function, set location to \"Charlotte, NC\", set property type to \"Retail\" and \"Industrial/Warehouse\", set minimum size to 50,000 sq ft, and extract all available listings with addresses, square footage, and neighborhood information.",
    "task_id": "2253155",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Signet Jewelers SIG most recent earnings call transcript Q4 2023 CEO CFO quotes guidance",
    "task_id": "1037670",
    "category": "Search"
  },
  {
    "confirmed_task": "Read webpage https://theethnicworld.com/buy-single-piece-wholesale-catalog-surat and follow the prompt: Extract all ethnic wear products from this page with complete details:\n\nFor each product, extract:\n1. Product name/title\n2. Price (in INR) \n3. Product description\n4. All available image URLs\n5. Product URL/link\n6. SKU or product ID if available\n7. Available sizes/colors if shown\n8. Stock status\n9. Category (determine from product name/description)\n\nFILTERING RULES:\n- Only include products with price > 1000 INR\n- Maximum 50 products\n- Skip products without clear pricing\n\nReturn as structured JSON array with format:\n[{\n    \"name\": \"Product Name\",\n    \"price_inr\": 1500,\n    \"price_usd\": 54.22,\n    \"description\": \"Product description\", \n    \"category\": \"Auto-detected based on product type\",\n    \"images\": [\"url1\", \"url2\"],\n    \"product_url\": \"full product page url\",\n    \"sku\": \"product_id\",\n    \"sizes\": [\"S\", \"M\", \"L\"],\n    \"colors\": [\"Red\", \"Blue\"],\n    \"in_stock\": true\n}]\n\nCalculate price_usd as (price_inr * 3) / 83\n\nCategorize products based on type: Sarees, Lehengas, Salwar Kameez, Gowns, Mens, Jewelry, etc.",
    "task_id": "2174924",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "go to this link 'https://www.airbnb.ca/rooms/715766776231493780/reviews' EXTRACT ALL THE REVIEWS of this property, you have to scroll down till the end of the page to LOAD ALL THE REVIEWS, DONT MISS ANY REVIEW. Display all reviews with their reviewer name, date, rating and full text.",
    "task_id": "1348833",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://pagespeed.web.dev/ and summarize content according to the following prompt: Analyze the performance of https://karpathy.ai using PageSpeed Insights. Focus on both mobile and desktop performance metrics. Extract Core Web Vitals and other key performance indicators.",
    "task_id": "1173252",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Procure na web, em qualquer site por 'PlayStation 5 1tb ' localize mais barato e me retorne o link de compra.",
    "task_id": "138566",
    "category": "Price Scraping"
  },
  {
    "confirmed_task": "Go to the website https://www.apartments.com/ and search for real estate\tGrok 3.5 (xAI): Search for real estate listings for homes/apartments for sale/rent in Burleson, TX. Scroll to the bottom of the page to ensure all listings are loaded. Filter the listings based on relevant criteria such as price range and location, and extract the key details (price, location, size, etc.) of all listings.\n",
    "task_id": "1609021",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "go to \"https://www.homedepot.com/b/Electrical/N-5yc1vZarcd?catStyle=ShowProducts\"\n\ncreate list with all products with quantity at stores in the sacramento area\nget price, quantity, price per unit, price per foot, name of product, url to product\n",
    "task_id": "1017678",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Goal: Find information about implementing SAML metadata management in Spring Boot applications\nBackground motivation: The user wants to learn how to implement SAML metadata management in a Spring Boot application, specifically how to generate SP metadata for IdPs and load/refresh IdP metadata, with code examples for both static and dynamic metadata management.\nExpected output format: Detailed information about SAML metadata management in Spring Boot, including code examples for generating SP metadata, loading IdP metadata, and implementing both static and dynamic metadata management approaches.\n\nCandidate URLs: \n- https://spring.io/projects/spring-security\n- https://docs.spring.io/spring-security/reference/servlet/saml2/\n- https://github.com/spring-projects/spring-security-samples/tree/main/servlet/spring-boot/java/saml2/login",
    "task_id": "1438924",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Find the current prices of Waterproof enclosures from Legrand and Schneider Electric. Include the model names and retailer websites. on https://www.google.com",
    "task_id": "929144",
    "category": "Price Scraping"
  },
  {
    "confirmed_task": "\n**Objective:** Scrape contact details for companies in specific WCA networks located in Hong Kong, sorted by name, limited to the first 10 unique companies found.\n\n**Detailed Steps:**\n1.  Navigate to https://www.wcaworld.com/directory (https://www.wcaworld.com/directory).\n2.  **Filtering - Networks:** Locate the 'Networks' filter section. Select *only* the following networks: 'WCA First', 'WCA China Global', 'WCA Advanced Professionals', and 'WCA Inter Global'. Ensure no other networks are selected.\n3.  **Filtering - Location:** Locate the 'Search:' field (likely for country/city). Input or select 'Hong Kong, China'.\n4.  **Sorting:** Locate the 'Order By' field. Select 'Company Name' from the options.\n5.  **Initiate Search:** Click the main 'Search' button to apply the filters and sorting.\n6.  **Load All Results:**\n    a. Wait for the initial search results page to load.\n    b. Repeatedly scroll down the page.\n    c. If a button labeled 'Click Here to Load More Results' becomes visible, click it.\n    d. Continue scrolling and clicking 'Load More' until the button no longer appears or is disabled, ensuring all companies are loaded onto the page. (Note: For this limited run, you might not need to load *all* results if 10 companies are found quickly).\n7.  **Scrape Company Details (Loop - Limited to 10):**\n    a. Initialize an empty list to store the URLs of company detail pages already visited.\n    b. Initialize a counter for scraped companies, set to 0.\n    c. Find all the clickable links representing individual company names in the search results.\n    d. For each company link found:\n        i.   If the scraped companies counter is already 10, **STOP** this loop and proceed to step 8.\n        ii.  Get the URL of the company detail page.\n        iii. If this URL is *not* in the visited list: \n             - Add the URL to the visited list.\n             - Increment the scraped companies counter.\n             - Click the company link/name to navigate to its detail page.\n             - **On the company detail page**, scrape the following 19 fields:\n                 - Company Info: association, association_id, company_name, branch_office, address, city, State, country, website, company_phone, company_fax, company_email\n                 - Contact Person Info: contact_name, contact_title, contact_email, contact_phone, contact_whatsapp, contact_wechat, contact_mobile\n             - Collect *all* contact persons listed on the detail page, creating a separate record for each contact (repeating company info).\n             - After scraping, navigate *back* to the search results page.\n        iv. If the URL *is* already in the visited list, skip this company and proceed to the next one.\n8.  **Format Output:** Consolidate all the scraped contact records (one per contact person, up to the 10-company limit) into a single JSON list of objects. Each object must contain all 19 fields specified above. Use an empty string \"\" for any missing values.\n9.  **Return:** Return *only* the final JSON list.\n",
    "task_id": "1356330",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "US-UK trade agreement provisions for e-commerce duty exemptions 2023",
    "task_id": "414191",
    "category": "Web Research"
  },
  {
    "confirmed_task": "\n\n    1) Objective\n    - Extract MITRE tags from the source: https://attack.mitre.org/matrices/enterprise/cloud/\n    - Based on the input json data.\n    2) Required Tags\n    - tactics\n    - techniques\n    - sub-techniques\n    - reasoning (a brief explanation of how the entries were identified)\n    3) Output Format\n    - Provide a JSON object containing the information above\n    4) JSON Output Template\n    {\n    \"tactics\": {\"id\":\"example\",\"name\": \"example\"},\n    \"techniques\": {\"id\":\"example\",\"name\": \"example\"},\n    \"sub-techniques\": {\"id\":\"example\",\"name\": \"example\"},\n    \"reasoning\": \"example\"\n    }\n\n    give me the analysis of the data:\n    {\n        \"id\": \"649bfb15326da22d0efca229\",\n        \"name\": \"Storage - Bucket Ransomware - Upload Encrypted File to Bucket\",\n        \"description\": \"This module interacts with the Google Cloud Storage service to perform various operations, including downloading files from a bucket, encrypting files using XOR encryption, uploading encrypted files to a bucket, and removing files from a bucket. It requires the necessary credentials to establish a connection and perform operations. Potential abuse of this functionality by an attacker could involve unauthorized access to files in the bucket, unauthorized encryption of files with malicious intent, unauthorized uploading of encrypted or malicious files to the bucket, or unauthorized removal of files from the bucket. This can lead to the storage of malicious or unauthorized content, data loss, compromise of sensitive information, or disruption of critical operations.\",\n        \"group\": \"Assume Breach [GCP]: SIEM Validation - Detection of High-Privilege Activities\"\n    }\n\n",
    "task_id": "202609",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Go to https://celltrader.co.za/shop/ it is a woocommerce store, Extract as much information as possible from each product saving the data each time. Scroll down 1 page at a time until you reach the end of the page. Go to the next page and do the same until there are no pages left",
    "task_id": "191902",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://artificialanalysis.ai and follow the prompt: Analyze this website comprehensively. Extract all information about API comparisons, pricing data, quality metrics, and performance benchmarks for text generation, image generation, and other AI services. Focus on identifying the top-performing APIs in terms of quality vs price ratio.",
    "task_id": "2202304",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Go to the website rrr.lt and switch to english language and find the cheapest generator for a 2015 Volkswagen Tiguan with a 2.0 TDI using sorting by price.",
    "task_id": "487971",
    "category": "Price Scraping"
  },
  {
    "confirmed_task": "Goal: Analyze authentication implementation and the main server entry point\nBackground motivation: Need to understand how authentication is implemented and how the server is initialized\nExpected output format: Detailed analysis of authentication implementation and server initialization code\n\nCandidate URLs: \n- https://github.com/makenotion/notion-mcp-server/blob/main/src/openapi-mcp-server/auth/index.ts\n- https://github.com/makenotion/notion-mcp-server/blob/main/src/init-server.ts\n- https://github.com/makenotion/notion-mcp-server/blob/main/src/openapi-mcp-server/index.ts",
    "task_id": "1327246",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Goal: Find information about how AWS S3 handles path traversal attempts with '../' in object keys from security perspective\nExpected output: Information about security considerations when using '../' in S3 object keys and any best practices or mitigations for potential path traversal risks\n\nCandidate URLs: \n- https://docs.aws.amazon.com/AmazonS3/latest/userguide/security-best-practices.html\n- https://aws.amazon.com/blogs/security/",
    "task_id": "1206209",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Read webpage https://play.google.com/store/apps/details?id=com.greentech.quran and follow the prompt: Extract competitive information about Al Quran (Tafsir & by Word) app including: rating, reviews, downloads, developer info, key features, pricing model, and what makes it unique compared to other Quran apps. Focus on competitive differentiation.",
    "task_id": "1766206",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "search https://www.redfin.com for homes in 70125 and find homes that have been on the market for 180 days are longer and that are multifamily also produce the Puppeteer script used to do this with a script",
    "task_id": "451705",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "You are tasked with researching e-SIM offers from Italian mobile operators and creating a comprehensive list of their offerings. Here is the list of operators to research:\n\nTIM\nVodafone\nWINDTRE\nIliad\nFastweb\nSky Mobile (powered by Fastweb)\n\nYour task is to search the official websites of these operators and collect information about their e-SIM offers. For each operator, you need to gather the following details:\n\n1. Name of the operator\n2. Whether they offer new e-SIMs or allow portability of existing numbers to e-SIMs\n3. Name of the e-SIM offer\n4. Monthly cost\n5. Activation cost\n6. SIM cost (if applicable)\n7. Due date of the offer \n8. Any constraints or special conditions (e.g., only for specific operator portability)\n\nCreate a list with this information for each operator that offers e-SIMs. Present the information in a clear, structured format using the following template for each entry:\n\n<operator_entry>\nOperator: [Name of the operator]\ne-SIM Type: [New e-SIM / Number portability to e-SIM / Both]\nOffer Name: [Name of the offer]\nMonthly Cost: [Cost in euros]\nActivation Cost: [Cost in euros]\nSIM Cost: [Cost in euros or \"Not applicable\"]\nContract Duration: [Duration or \"No contract\"]\nConstraints: [List any special conditions or \"None\"]\n</operator_entry>\n\nIf an operator does not offer e-SIMs or if you cannot find information about their e-SIM offers, include them in the list with a note stating that e-SIM information is not available.\n\nIf you encounter any difficulties finding information or if a website is not accessible, make a note of it in your response.\n\nPresent your findings in a clear, organized manner, listing each operator's information separately. Begin your response with an introductory sentence and end with a brief summary of your findings.",
    "task_id": "171840",
    "category": "Web Research"
  },
  {
    "confirmed_task": "\n    1. Navega a google maps\n    2. busca clinica dental en quillota\n    3. ingresa en los primeros 5 resultados. \n    4. A cada resultado le vas a sacar los datos de contactos\n    ",
    "task_id": "249664",
    "category": "Search Results Extracting"
  },
  {
    "confirmed_task": "Goal: Find detailed information about the GHSA-grv7-fg5c-xmjg vulnerability in braces 3.0.2\nExpected output: Comprehensive details about the vulnerability in braces 3.0.2, including technical explanation, impact, and remediation.\n\nCandidate URLs: \n- https://github.com/advisories/GHSA-grv7-fg5c-xmjg\n- https://www.cve.org/CVERecord?id=CVE-2019-10742\n- https://www.npmjs.com/advisories/786",
    "task_id": "1201249",
    "category": "Web Research"
  },
  {
    "confirmed_task": "In-depth competitor analysis for ThoughtSpot, Qlik Insight Advisor, Sisense, Kyligence, Microsoft Power BI (natural language query feature), and Tableau Ask Data focusing on their pricing tiers, architecture, NLP capabilities, data visualization, security compliance, and target market segments",
    "task_id": "1201555",
    "category": "Web Research"
  },
  {
    "confirmed_task": "\n        Find the website for Georgia Superior Court Clerks' Cooperative Authority (GSCCCA) UCC Filings and search for the company '1 OAK Roofing' using the method: Search the GSCCCA UCC index by debtor name ('1 OAK Roofing'). Expected documents: UCC-1 Financing Statements, UCC-3 Amendments/Continuations/Terminations..\n        Extract the following attributes: debtor information (company name, address), secured party information, associated individuals (potential owners/management hints from filing details).\n        Export all found information in structured JSON format.\n        You must include the URL you extracted the data from in the results.\n        Do not try to login to any website. You do not have credentials for any login.",
    "task_id": "1220939",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "data center transactions europe list 2020-2024 report site:.cbre.com OR site:.savills.com OR site:.jll.com OR site:.cushmanwakefield.com",
    "task_id": "907171",
    "category": "Search Results Extracting"
  },
  {
    "confirmed_task": "\n        Go to https://www.machinerytrader.com/listings/search?Category=1055&sort=9\n\n        If a captcha is encountered, wait, I will solve it, then continue.\n\n        For each page of search results (at least 5 pages):\n            Extract all skid-steer listings that are in these states: ['Idaho', 'Utah']\n\n            For each matching listing, immediately output the following information in JSON format:\n            {\n                \"category\": \"The category (e.g. Track Skid Steers, Wheel Skid Steers)\",\n                \"equipment_name\": \"The equipment name/model\",\n                \"hours\": \"Number of hours on the machine\",\n                \"current_bid\": \"Current bid if available\",\n                \"price\": \"Price if available\",\n                \"num_bids\": \"Number of bids on the item\",\n                \"time_remaining\": \"Time remaining in auction\",\n                \"location\": \"Location (city and state)\",\n                \"seller_name\": \"Seller name\",\n                \"seller_phone\": \"Seller phone number\",\n                \"auction_url\": \"The URL of this specific auction\"\n            }\n\n            Output each listing as soon as you find it, don't wait to collect all listings.\n            Do not include any \"Mini Skid Steers\" in the results.\n\n            After outputting a listing, continue to the next one.\n\n            After processing all listings on a page, go to the next page and repeat.\n        ",
    "task_id": "944335",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Develop a robust web scraping script to systematically extract detailed business information from the Better Business Bureau (BBB) website for companies categorized under \"Access Control Systems\" across all available pages. The script should efficiently handle pagination, collect unique business profile URLs, and extract specified data fields from each profile. The final dataset should be stored in a structured JSON file.\n\nDetailed Requirements:\n\nPagination Handling:\n\nInitiate the scraping process at the following URL:\nperl\nCopy\nEdit\nhttps://www.bbb.org/search?find_country=USA&find_text=access%20control%20systems&find_type=Category&page=1&sort=Relevance\nImplement logic to navigate through all search result pages by incrementing the page parameter until no further results are available.\nBusiness Profile URL Collection:\n\nOn each search results page, identify and collect the URLs of individual business profiles.\nStore these URLs in a list, ensuring that each URL is unique by removing duplicates.\nData Extraction from Business Profiles:\n\nFor each unique business profile URL, access the page and extract the following information:\nBusiness Name: The official name of the business.\nWebsite URL: The business's website address.\nPhone Number: Contact phone number.\nCategory: Business category (e.g., Access Control Systems).\nAddress: Physical address of the business.\nData Storage:\n\nOrganize the extracted data into a JSON file, with each business entry structured as follows:\njson\nCopy\nEdit\n{\n  \"business_name\": \"Example Business Name\",\n  \"website_url\": \"http://www.example.com\",\n  \"phone_number\": \"(123) 456-7890\",\n  \"category\": \"Access Control Systems\",\n  \"address\": \"1234 Example St, City, State, ZIP\"\n}\nError Handling and Logging:\n\nImplement robust error handling to manage scenarios such as missing data fields, HTTP errors, or timeouts.\nMaintain a log file to record the status of each processed URL, including any errors encountered, to facilitate debugging and ensure data integrity.\nCompliance and Ethical Considerations:\n\nEnsure that the scraping activities comply with the BBB's terms of service and legal guidelines.\nImplement respectful crawling practices by including appropriate delays between requests to avoid overwhelming the website's servers and to mimic human browsing behavior.\nAdditional Considerations:\n\nEfficiency: Optimize the script to minimize execution time while ensuring thorough data collection.\nScalability: Design the script to handle a large number of listings and pages without performance degradation.\nMaintainability: Write clean, well-documented code to facilitate future updates or modifications.\nBy adhering to these detailed requirements, the script will effectively gather and store comprehensive information on businesses offering access control systems, facilitating further analysis or utilization of the data as needed.",
    "task_id": "503786",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Goal: Find technical details of the vulnerability from GitHub or the original pull request that fixed it\nBackground motivation: I need to find the specific technical details of the vulnerability from the source, including the exact fix that was applied and any discussions around it.\nExpected output format: Technical details of the vulnerability, including code snippets if available, the exact fix implemented, and any discussions from the maintainers about the vulnerability.\n\nCandidate URLs: \n- https://github.com/ljharb/qs/pull/428\n- https://github.com/n8tz/CVE-2022-24999",
    "task_id": "1704522",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Search for the latest suggested phones on amazon.com and extract details including names, specifications, and prices.\n\nExpected Output: A list of latest suggested phones with names, specifications, and prices.",
    "task_id": "448768",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Go to \"https://www.tenderned.nl/aankondigingen/overzicht\", search for \"Digitale Transformatie\". For each posting in the list open the page and extract title, description and the value of the contract. The page is in Dutch.\n",
    "task_id": "1513697",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "You are a helpful assistant that visits web pages and extracts relevant information about enzyme transformations of n-Hexane, including enzyme names, EC numbers, genes/proteins, transformation reactions, and resulting metabolites. Visit the NCBI Bookshelf page about n-Hexane toxicity and extract detailed information about its metabolism, focusing on enzyme transformations, enzyme names, EC numbers, genes/proteins involved, and metabolic pathways.",
    "task_id": "1380258",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Get AI bills introduced in the current congress.",
    "task_id": "26655",
    "category": "Search"
  },
  {
    "confirmed_task": "Search for ZTE Corporation's 2023 annual report to analyze its financial data.",
    "task_id": "1298471",
    "category": "File Download"
  },
  {
    "confirmed_task": "site:pertanian.go.id ISPO certified companies list oil palm plantation coordinates polygons",
    "task_id": "1019626",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "email address or contact form for restaurants listed on restaurantsofmanchester.com",
    "task_id": "808075",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "go to mercadolivre.com.br,\ncheck for the best price for iphone 11, \ncolect data of 10 products.\n",
    "task_id": "294019",
    "category": "Price Scraping"
  },
  {
    "confirmed_task": "\n            Task: Scrape property listings from a pre-filtered Yad2 search results page\n\n            Step 1: Go directly to this URL: https://www.yad2.co.il/realestate/rent?multiNeighborhood=855%2C159%2C163&rooms=2-3&price=4000-8000&zoom=14\n            \n            Step 2: Wait for the page to fully load with all property listings\n            \n            Step 3: Extract detailed data from each property listing:\n            - Property ID (from listing URL or data attribute)\n            - Title (property type and rooms)\n            - Price\n            - Address (City, Neighborhood, Street)\n            - Property details (Type, Rooms, Floor, Area in sq.m)\n            - Image URLs\n            - Description (full text)\n            - Date listed\n            - Contact information (name, phone if available)\n            \n            Step 4: Check if there are more pages and note whether there's a next page\n            \n            IMPORTANT: Format each listing with \"LISTING START\" and \"LISTING END\" markers so I can parse them.\n            Include the full details in a structured format like:\n            LISTING START\n            ID: [id]\n            Title: [title]\n            Price: [price]\n            City: [city]\n            Neighborhood: [neighborhood]\n            Street: [street]\n            Type: [property type]\n            Rooms: [rooms]\n            Floor: [floor]\n            Area: [area]\n            Description: [description]\n            Date Listed: [date]\n            Contact: [name]\n            Phone: [phone]\n            Images: [urls]\n            LISTING END\n            ",
    "task_id": "1063981",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://www.susannabeatrice.global and follow the prompt: Extract all website content including text, services offered, about/biography information, contact details, portfolio/work examples, testimonials, and any other relevant content that can be used to populate a website. Also analyze any branding elements, color schemes, and content structure.",
    "task_id": "2252317",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "go to amazon.com and search for puma shoes.\nafter scape the data of first 15 result of shoes. Get their images, title, description and price of each shoes.\nOutput data must be in tabular format.",
    "task_id": "372770",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Extract the following information from the provided product page:\nURL: https://www.adidas.jp/%E3%82%B3%E3%83%BC%E3%83%89%E3%82%AB%E3%82%AA%E3%82%B9-%E3%83%9C%E3%82%A2-25-codechaos-boa-25/IH5142.html?pr=product2_rr&slot=2&rec=ds\n\n- `optionGroups`: A list of option groups available for the product. Each option group contains:\n  - `name`: The name of the option group (e.g., Colours, Sizes).\n  - `options`: A list of options in the group. Each option contains:\n    - `name`: The name of the option (e.g., Black, Medium).\n    - `imageUrl`: The URL of the image associated with the option, if available.",
    "task_id": "225377",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\n            Find the website for Pennsylvania Department of State - Corporation Bureau or use Google to search for the Core Roofing on Pennsylvania Department of State - Corporation Bureau (this method works best with non goverment websites such as linkedin).\n            Search for the company 'Core Roofing' with context: {\"location\": \"289 W Uwchlan Jave, Downingtown PA 19335\"} using the method: Search by company name 'Core Roofing' and/or address '289 W Uwchlan Jave, Downingtown PA 19335'. If available, search by business ID or registration number. Check for variations of the name (e.g., Core Roofing LLC, Core Roofing Inc.)..\n            Extract the following attributes: registered agent, officers, directors, entity status, business type, date of incorporation/formation.\n            Export all found information in structured JSON format.\n            You must include the URL you extracted the data from in the results.\n            Do not try to login to any website. You do not have credentials for any login.  \n            If at any point you get blocked by cloudflare, attempt to bypass it.  If you are unable to do so STOP.",
    "task_id": "1291834",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\nYou are a compliance analyst specialized in e-commerce due diligence.\nYou havr to gather key information to enable a compliance analyst to assess if a website is a dropshipping website.\nBrowse the folowing url:argotstudio.com\nReturn the following information. You need to actuelly return the information, not a link to the information.\n- location: is there a physical address of the company or the warehouse ? Could you determine from where the website is operated ?\n- return policy: read the return policy and describe it. In particular, are returns allowed ? Are they charged ?\n- delivery time: read the delivery policy or the FAQ, or the terms and conditions. what are the typical delivery times ? If delivery times are long (>1 week), is it justified ?\n- product photo: are the product photos generic ? Could the product be sold on aliexpress ? You can go on aliexpress if needed.\n",
    "task_id": "1501614",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Goal: Find information about China's National Intelligence Law and requirements for companies to assist with state intelligence work\nBackground motivation: Need to understand specific legal requirements for Chinese companies to cooperate with government authorities and share data when requested\nExpected output format: Specific articles and provisions from China's National Intelligence Law requiring companies to cooperate with authorities, along with analysis of implications\n\nCandidate URLs: \n- https://www.lawfareblog.com/beijings-new-national-intelligence-law-defense-offense\n- https://digitalcommons.law.scu.edu/cgi/viewcontent.cgi?article=3169&context=historical\n- https://thediplomat.com/2019/02/the-real-danger-of-chinas-national-intelligence-law/",
    "task_id": "1748573",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "1. Go to Google Maps Preview\n2. Search for \"BP Rotterdam Europoort\" click on the first recommendation below the searchbox and wait for the map to update\n3. Click on the \"Hotels\" button\n4. Search for \"vakantiepark\" in the search field\n5. For each result in the list:\n   - Click on Ergebnisse list\n   - Extract all available information including:\n     * Name\n     * Address\n     * Rating\n     * Number of reviews\n     * Email (if available)\n     * Phone number\n     * Website\n     * Description\n6. Save all collected data in a structured JSON format using the Accommodation model",
    "task_id": "227142",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\nTask: Get 10 vendors with name, email, address, contact_no, rating, and vendor_distance.\nRetrieve complete details for the 10 bicycle tire repair vendors near Uppsala, 75332, prioritizing email extraction. At least 10 vendors must include validated emails.\n\nSearch & Initial Data Collection:\n1. Search Google Maps for \"Bicycle tire repair service vendors in Uppsala, 75332\".\n2. Collect the top 10 closest vendors with:\n   - vendor_name\n   - address\n   - contact_no\n   - rating (e.g., \"4.5\")\n   - vendor_distance (e.g., \"1.2 km\")\n   - listed_website (if available on Google Maps).\n\nStep 1: For vendors with a listed website:\n   - Click on the vendor's listing to access their detailed information.\n   - Navigate to the listed website.\n   - Collect the website links for each vendor.\n   - If no website is listed, proceed with the next vendor.\n\nOutput Requirements:\n{\n  \"vendors\": [\n    {\n      \"vendor_name\": \"Example Vendor\",\n      \"website\": \"http://www.examplevendor.com\",\n      \"contact_no\": \"+46 18-123 4567\",\n      \"address\": \"Street 1, 75332 Uppsala\",\n      \"rating\": \"4.6\",\n      \"vendor_distance\": \"0.5 km\"\n    },\n    ...\n  ]\n}\n",
    "task_id": "325376",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Extract job listings from the Upwork job search page. For each job, go to the job page, extract the title, description, budget, and number of applicants. Then move on to the next job and repeat the process.",
    "task_id": "1100384",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://tris.vn/ and follow the prompt: Analyze this website comprehensively. Extract:\n1. Overall layout and structure\n2. Content sections and their hierarchy\n3. Current design elements (colors, fonts, styling)\n4. Navigation structure\n5. Key features and functionality\n6. Images and media used\n7. Any interactive elements\n\nProvide a detailed analysis of the website's current state so I can recreate and improve it.",
    "task_id": "2118996",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "On the URL https://www.amazon.com/, search for the item 'Apple MacBook Air 13.3 inch Laptop' and verify that adding it to the cart works properly if the item is not in stock.",
    "task_id": "933960",
    "category": "UI Testing"
  },
  {
    "confirmed_task": "Visit the URL https://verificacfdi.facturaelectronica.sat.gob.mx/default.aspx?id=B4BB65A2-3346-4988-BB10-124524B20148&re=PMO131216PM8&rr=XAXX010101000&tt=369900.000000&fe=HIl4RQ== solve the captcha, and return the table as JSON",
    "task_id": "453534",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "On the current Amazon Best Sellers in Books page, identify all book listings. Each book listing is typically marked with a rank (e.g., #1, #2). For each book listing, extract the following information:\n1.  **Title**: The main, larger text link for the book.\n2.  **Author**: The smaller text directly below the title.\n3.  **Review_Count**: The number located next to the star rating.\n4.  **Price**: The value that starts with a dollar sign ($).\nPresent the extracted information as a list of JSON objects. Each object should represent a book and contain the keys 'Title', 'Author', 'Review_Count', and 'Price'. Ensure all books visible on the current page are extracted.",
    "task_id": "2143378",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\n    Go to https://szigetfestival.com/en/tickets and scrape the webpage to extract all available ticket pricing information. For each ticket type, collect the ticket name, price, ticket category (e.g., day pass, multi-day pass, camping upgrade), availability status, and any relevant descriptions or benefits associated with the ticket. If the page uses dynamic content loading, ensure all ticket options are fully visible before scraping. This may involve scrolling or waiting for JavaScript-rendered elements to finish loading.\n\n    If there is a cookie consent banner or other interactive element that blocks the page content, dismiss it to allow full access to the ticket listings. Make sure all pricing details are accurately captured, including multiple pricing tiers or early bird offers where applicable. Avoid duplicates and confirm that all necessary information is parsed correctly.\n\n    Return the extracted data in a structured format such as JSON or CSV, with clear and descriptive field names like ticket_name, category, price, availability, and description to ensure readability and usability.",
    "task_id": "1122929",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\ngo to this url and give me the Complete balance sheet of this company : https://www.tcs.com/content/dam/tcs/investor-relations/financial-statements/2023-24/ar/annual-report-2023-2024.pdf\n",
    "task_id": "976402",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\nApartment Search Parameters:\nLocation: Lake Colony\n\n\nRequired Information:\n1. Property Details\n   - Management company (verify if managed by listed partners)\n   - Building address\n   - Property contact information\n   - Year built/renovated\n\n2. Unit Information\n   - Available floor plans\n   - Square footage ranges\n   - Price ranges\n   - Lease terms\n   - Current availability status\n\n3. Amenities & Features\n   - Building amenities\n   - In-unit features\n   - Parking options\n   - Pet policy\n\n4. Leasing Requirements\n   - Application process\n   - Security deposit\n   - Income requirements\n   - Move-in fees\n   - Required documentation\n\n5. Virtual Tour/Photos\n   - Unit interior photos\n   - Common area photos\n   - Building exterior photos\n   - Community amenity photos\n\nFormat Requirements:\n- Organize information in clear, hierarchical sections\n- Include direct contact information for leasing office\n- Note any special offers or promotions\n- Include reference to verified management company\n",
    "task_id": "264673",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Read webpage https://www.amazon.co.uk/s?k=smart+lighting&crid=2X3W4Z8Z4ZJ8X&sprefix=smart+lighting%2Caps%2C182&ref=nb_sb_noss_1 and follow the prompt: From this search results page, extract a list of smart lighting products, including the product title, price, and the name of the seller.",
    "task_id": "2215919",
    "category": "Search Results Extracting"
  },
  {
    "confirmed_task": "\n\n### Step 1: Navigate to the website\n- Open [RBI Bulletin] (https://www.rbi.org.in/Scripts/BS_ViewBulletin.aspx)\n\n### Step 2: Open Bulletins for year - 2025 and month - 1\n- Click on 2025\n- click on 1 under the list\n\n### Step 3: Open Excel File attached to heading 'Select Economic Indicators' under heading 'Current Statistic General'\n- Open excel attachment associated with heading 'Select Economic Indicators' under heading 'Current Statistic General'\n- Extract latest Policy Repo Rate\n\n\n",
    "task_id": "1612606",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://remote.team/en/ and follow the prompt: Analyze this website comprehensively. I need to understand:\n1. Overall structure and navigation\n2. All main pages and sections\n3. Content types and layouts\n4. Interactive features and functionality\n5. Design elements, colors, typography\n6. Any forms or dynamic content\n7. Footer and header elements\n\nPlease explore multiple pages to get a complete understanding of the site architecture.",
    "task_id": "1960499",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Revised Prompt:\n\nObjective:\n\nAutomate the process of searching the California Attorney General's Proposition 65 60-Day Notice Search website for active or past legal cases filed against a specific company, focusing on whether those cases involve specific products. Extract relevant case information first, then match against the provided product list, and finally, output the results in a structured JSON format.\n\nInputs:\n\ncompany_name: The name of the company to search for (string).\nproducts: A list of exact product names to check for in the case records (list of strings).\nWorkflow:\n\nPrepare Company Name:\n\nTake the input company_name.\nRemove any of the following corporate suffixes from the end of the name (case-insensitive): Inc, Incorporated, Corp, Corporation, LLC, Ltd, Limited, PLC.\nTrim any leading/trailing whitespace from the resulting name.\nUse this cleaned name for the search.\nExample: \"Mezzaten Inc\" becomes \"Mezzaten\"; \"GreenWorld LLC\" becomes \"GreenWorld\".\nNavigate and Search:\n\nNavigate and Search:\nGo to the specified URL: https://oag.ca.gov/prop65/60-day-notice-search\nLocate the \"Search Notices\" section of the page, specifically the form containing the \"Defendant Name\" input field. Ensure this section is interactable (simulating scrolling if necessary to bring it fully into view).\nInput the cleaned company name into the \"Defendant Name\" field within this specific form.\nCrucially: Do not input any values into any other search fields (like Date Received, Source, Noticing Party, etc.) within this form. Leave them blank.\nInitiate the search. This is very important: There may be multiple 'Search' buttons on the page. You must click the specific 'Search' button that is directly associated with the 'Search Notices' form (the form containing the 'Defendant Name' field you just filled) and is typically located at the bottom of that specific form section. Do not click any other search buttons on the page.\nWait for the search results table, associated with the \"Search Notices\" form, to load completely.\n\nInitialize an empty list to store details from all found cases (e.g., extracted_cases).\nSystematically process the search results:\nIf results span multiple pages, navigate through every page.\nFor each row (representing a single case notice) in the results table on all pages:\nExtract the value from the \"Date Received\" column. Store this as date_filed.\nExtract the exact text from the \"Source\" column. Store this as source_text.\nAdd an object or record containing { \"date_filed\": date_filed, \"source_text\": source_text } to the extracted_cases list.\nContinue this extraction until all cases across all pages for the given company search have been processed.\nMatch Products and Prepare Output Data:\n\nInitialize an empty list for the final output structure (e.g., output_product_list).\nIterate through each product_name provided in the input products list.\nFor the current product_name:\nSearch within the extracted_cases list (collected in Step 3) for any entry where the source_text exactly matches the current product_name.\nIf a match is found:\nIdentify the corresponding date_filed from the first matching entry found in extracted_cases.\nCreate a result object: { \"product_name\": product_name, \"date_filed\": matched_date_filed, \"case_filed\": true }\nAdd this object to the output_product_list.\nIf no match is found after checking all entries in extracted_cases:\nCreate a result object: { \"product_name\": product_name, \"case_filed\": false }\nAdd this object to the output_product_list.\nGenerate Final Output:\n\nConstruct the final JSON object using the output_product_list prepared in Step 4. The structure must be:\nJSON\n\n{\n  \"products\": [\n    // ... entries from output_product_list go here\n  ]\n}\nFinal Execution Rules:\n\nEnsure all interactions target the correct elements on the webpage, especially the \"Defendant Name\" field within the \"Search Notices\" section.\nHandle potential loading delays gracefully when waiting for search results and navigating pages.\nOnce the final JSON output is constructed based on the complete analysis of extracted cases against the input product list, terminate the process immediately.\nDo not perform any further actions, searches, or retries after generating the output.",
    "task_id": "1662847",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "I am in Hyderabad, India. Can you find out the best price to buy a Mac Book M3 with 32 GB Ram and 1 TB hard disk. ",
    "task_id": "487739",
    "category": "Price Scraping"
  },
  {
    "confirmed_task": "Extract absolutlyall the information related mobiles offers of a telecom operator.\n    extract informations only from URLs (take the value off this URLS) :\"{\\\"names\\\": [\\\"Forfait Free 5G\\\", \\\"S\\u00e9rie Free\\\", \\\"Forfait 2\\u20ac\\\", \\\"Free Flex\\\"], \\\"URLs\\\": [\\\"//mobile.free.fr/fiche-forfait-free\\\", \\\"//mobile.free.fr/fiche-forfait-serie-free\\\", \\\"//mobile.free.fr/fiche-forfait-2-euros\\\", \\\"//mobile.free.fr/free-flex\\\"]}\". \n    Your role is to extract all the details from these URLs by mobile offer name. \n    You need to go through each URL to complete all the information about these mobile offers.\n    Your final answer must be in a json format",
    "task_id": "769424",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Navigate to https://www.eib.org/en/projects/pipelines/all/20230590 and extract links to tender-specific documents such as project specifications, technical drawings, or contractual agreements. Ignore irrelevant documents such as terms and conditions, privacy policies, and marketing brochures. Also ignore domain-brad documents.",
    "task_id": "1202901",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\nYou are an automated end to end tester of an e-commerce company specialising in healthcare called TATA 1mg. TATA 1mg has a website which needs to be tested for any anomaly. In this particular scenario you need to test if certain widget have valid items in them or not. Following are the steps you need to perform:\n1. Go to 1mg.com\n2. Close the full screen banner by clicking on cross icon\n3. Stay on homepage\n4. Scroll homepage until you find a widget called `Healthcare devices - top brands`\n5. Click on 1st item in the widget called `Healthcare devices - top brands`\n6. New page should be displayed correctly.\n\nExpected behaviour:\n1. Page should not display an error\n2. Page should have products listed. Empty product results is an anomaly\n3. Page should have filters on the left.\n\nPlease report of expected behaviour is not observed. Report how many products are visible on the page without scrolling in first fold.\n\n",
    "task_id": "457947",
    "category": "UI Testing"
  },
  {
    "confirmed_task": "go to https://www.comparefirst.sg, click term insurance, click non-DPI, set date of birth as 01/01/1990, gender male, smoker no, select policy term 21 to 30,  sum assured 1,000,000, critical illness NO, then search and extract all the insurancce companies quotes and summarise into a csv file on the company name, premium rate, policy term",
    "task_id": "426639",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "1. Go to url https://www.nseindia.com/companies-listing/corporate-filings-financial-results-comparision\n\t\t\t2. type Tata Consultancy Services Limited in company name\n\t\t\t3. seclect name from dropdown\n\t\t\t4. press search\n\t\t\t5. extract data in the table,\n\t\t\t6. scroll till you capture whole table\n\t\t\t7. parse in json format.\n\t\t\t",
    "task_id": "265470",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\n    **Job Search Instructions**\n    1. Google Search:\n       - Search: 'site:linkedin.com OR site:glassdoor.com AI Engineer jobs in Pakistan'\n       - If any pop-ups appear (cookies, newsletters, sign-in prompts):\n         * Immediately close using X button\n         * Never accept or subscribe\n         * If multiple pop-ups, close sequentially from top-right\n    \n    2. Link Navigation:\n       - First collect 3 LinkedIn job links from search results\n       - Then collect 3 Glassdoor job links\n       - Prioritize links with:\n         * Job title matching search terms\n         * Recent post dates (<7 days)\n         * Direct apply options\n    \n    3. Job Page Interaction:\n       For each visited job page:\n       a. Close any overlay pop-ups within 2 seconds\n       b. Scroll through entire job description\n       c. Extract these details:\n          - job_title (text)\n          - company (employer name)\n          - experience (required years)\n          - jobNature (Full-time/Part-time)\n          - location (specific office address)\n          - salary (range or exact figure)\n          - apply_link (direct URL)\n        d: if these details are not found click the job and try to extract information\n    \n    4. Data Structure:\n       Return exactly 6 jobs (3 LinkedIn + 3 Glassdoor) as:\n       [\n         {\n           \"job_title\": \"Python Developer\",\n           \"company\": \"Tech Corp\",\n           \"experience\": \"3-5 years\",\n           \"jobNature\": \"Full-time\",\n           \"location\": \"New York, NY\",\n           \"salary\": \"$80,000 - $120,000\",\n           \"apply_link\": \"https://linkedin.com/job/123\"\n         },\n         ...\n       ]\n       Ensure valid JSON format with double quotes else all the data will be invain incase of failure go throuth the response and extract information from response of the searchs activity\n    ",
    "task_id": "930386",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\n            Find the website for Tennessee Department of Commerce and Insurance or use Google to search for the Armor Roofing of Tennessee on Tennessee Department of Commerce and Insurance (this method works best with non goverment websites such as linkedin).\n            Search for the company 'Armor Roofing of Tennessee' with context: {\"location\": \"545 N Mt Juliet Rd Suite 1201 TN Mount Juliet 37122 US\"} using the method: Search for 'Armor Roofing of Tennessee' in the department's licensing database to verify roofing contractor licenses and any associated information..\n            Extract the following attributes: licenses, certifications, disciplinary actions.\n            Export all found information in structured JSON format.\n            You must include the URL you extracted the data from in the results.\n            Do not try to login to any website. You do not have credentials for any login.  \n            If at any point you get blocked by cloudflare, attempt to bypass it.  If you are unable to do so STOP.",
    "task_id": "1254332",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\n    Strictly call the  search_google_fetch_links tool for the following task:\n    Call the search_google_fetch_links tool seperately for each question\n    There are multiple questions to search for legal  in **Customer Reviews & Ratings:**\n\n* \"Sojuba Restaurant reviews on Google\"\n* \"Sojuba Restaurant reviews on Yelp\"\n* \"Sojuba Restaurant reviews on TripAdvisor\"\n* \"Sojuba Restaurant customer complaints site:bbb.org\"\n* \"Sojuba Restaurant scam or legit?\"\n* \"Sojuba Restaurant ratings\"\n* \"Sojuba Restaurant customer service reviews\"\n\n\n**News & Media Sentiment:**\n\n* \"Sojuba Restaurant controversy OR scandal\"\n* \"Sojuba Restaurant lawsuit\"\n* \"Latest news about Sojuba Restaurant\"\n* \"Public reaction to Sojuba Restaurant in 2023\"  (Replace 2023 with relevant years)\n* \"Sojuba Restaurant negative reviews\"\n* \"Sojuba Restaurant positive reviews\"\n\n\n**Social Media & Public Opinion:**\n\n* \"Twitter reactions to Sojuba Restaurant\"\n* \"What people are saying about Sojuba Restaurant on Reddit\"\n* \"Trending hashtags about Sojuba Restaurant\"\n* \"Sojuba Restaurant #[relevant hashtag, if known]\" (e.g., #SojubaRestaurant #foodie)\n* \"Sojuba Restaurant customer service Twitter complaints\"\n\n\n**Competitor Comparisons (assuming a competitor exists):**\n\n* \"Sojuba Restaurant vs [Competitor Restaurant Name] reviews\"\n* \"Is Sojuba Restaurant better than [Competitor Restaurant Name]?\"\n* \"Sojuba Restaurant vs [Competitor Restaurant Name] customer satisfaction\"\n\n\n**Important Considerations for Refinement:**\n\n* **Location:**  Adding the location (e.g., \"Sojuba Restaurant reviews Chicago\") will significantly refine results and target local sentiment.\n* **Specific aspects:**  If you want to focus on a particular aspect (e.g., food quality, service), add that to the search query (e.g., \"Sojuba Restaurant food quality reviews\").\n* **Timeframe:**  If you need sentiment data from a specific period, add that to the query (e.g., \"Sojuba Restaurant reviews 2023\").\n    \n    Aggregate all the URLs fetched and send as response.\n    Ensure the URLs are present only regarding the **Customer Reviews & Ratings:**\n\n* \"Sojuba Restaurant reviews on Google\"\n* \"Sojuba Restaurant reviews on Yelp\"\n* \"Sojuba Restaurant reviews on TripAdvisor\"\n* \"Sojuba Restaurant customer complaints site:bbb.org\"\n* \"Sojuba Restaurant scam or legit?\"\n* \"Sojuba Restaurant ratings\"\n* \"Sojuba Restaurant customer service reviews\"\n\n\n**News & Media Sentiment:**\n\n* \"Sojuba Restaurant controversy OR scandal\"\n* \"Sojuba Restaurant lawsuit\"\n* \"Latest news about Sojuba Restaurant\"\n* \"Public reaction to Sojuba Restaurant in 2023\"  (Replace 2023 with relevant years)\n* \"Sojuba Restaurant negative reviews\"\n* \"Sojuba Restaurant positive reviews\"\n\n\n**Social Media & Public Opinion:**\n\n* \"Twitter reactions to Sojuba Restaurant\"\n* \"What people are saying about Sojuba Restaurant on Reddit\"\n* \"Trending hashtags about Sojuba Restaurant\"\n* \"Sojuba Restaurant #[relevant hashtag, if known]\" (e.g., #SojubaRestaurant #foodie)\n* \"Sojuba Restaurant customer service Twitter complaints\"\n\n\n**Competitor Comparisons (assuming a competitor exists):**\n\n* \"Sojuba Restaurant vs [Competitor Restaurant Name] reviews\"\n* \"Is Sojuba Restaurant better than [Competitor Restaurant Name]?\"\n* \"Sojuba Restaurant vs [Competitor Restaurant Name] customer satisfaction\"\n\n\n**Important Considerations for Refinement:**\n\n* **Location:**  Adding the location (e.g., \"Sojuba Restaurant reviews Chicago\") will significantly refine results and target local sentiment.\n* **Specific aspects:**  If you want to focus on a particular aspect (e.g., food quality, service), add that to the search query (e.g., \"Sojuba Restaurant food quality reviews\").\n* **Timeframe:**  If you need sentiment data from a specific period, add that to the query (e.g., \"Sojuba Restaurant reviews 2023\"). and the others are removed\n    Do not provide support links,advertisement links\n    \n    ",
    "task_id": "1328722",
    "category": "Search Results Extracting"
  },
  {
    "confirmed_task": "go to www.autotrader.co.uk\naccept all cookies\nuse the \"find your perfect car\" form\nenter a postcode of BT817YJ\nselect volkswagen from the list of makes\npause for a few seconds to allow the model list to update\nselect id.4 from the list of models\nfrom the list of max price select the price nearest to 20000\nsearch the available cars and list them including the price, the cost, their location and a link to the URL for the ad for the car\n",
    "task_id": "1024420",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "'You are a professional job finder.\n\t\t\t\tGo to https://upwork.com then: \n\n\t\t\t\t'find Python Django jobs on Upwork.com and save them to a file'\n\t\t\t\tImportant:\n\t\t\t\t- Wait for each element to load before interacting\n\t\t\t\t- Make sure the application is typed exactly as shown\n\t\t\t\t- Verify the post button is clickable before clicking\n\t\t\t\tllm=ChatOpenAI(model=\"gpt-4o\"),\n\t\t\t\tbrowser_context=browser_context,\n\t\t\t\t",
    "task_id": "919843",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://www.allabolag.se/segmentering and follow the prompt: Try a different approach to find HVAC companies with high revenue:\n1. First, apply the HVAC industry filter (Ventilation, luftbehandling)\n2. Try setting the revenue filter with different values or methods (500000000, 500,000,000, or 500 miljoner SEK)\n3. If revenue filter doesn't work properly, get the list of all HVAC companies and then sort by revenue\n4. Look for the largest companies in the HVAC sector and identify those with revenue above 500M SEK\n5. Extract company names, revenue figures, and basic information",
    "task_id": "2185648",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Go to https://www.autotrader.ca/dealersearch/ and extract dealer information from multiple pages.\n\n1. For each dealer card on the current page, extract:\n   - Dealer name (e.g., \"613 Motorz\", \"613 Rides\")\n   - Website URL - Look for and click \"View Dealer Website\" button if available (THIS IS THE MOST IMPORTANT)\n   - Complete address including postal code\n   - Phone number\n\n2. After extracting all dealers from the current page:\n   - Instead of clicking pagination controls, construct a direct URL for the next page\n   - Use this URL pattern: https://www.autotrader.ca/dealersearch/?pg=N where N is the page number\n   - For example, page 2 would be: https://www.autotrader.ca/dealersearch/?pg=2\n   - Navigate to this URL using go_to_url action\n   - Wait for the new page to load completely\n\n3. Repeat steps 1-2 for at least 5 pages (pages 1-5), using the direct URL approach for navigation.\n\nIMPORTANT: Do NOT try to click pagination controls - the site uses Angular and the pagination may not be easily clickable. Instead, directly modify the URL with the pg parameter to navigate to different pages.",
    "task_id": "1099868",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Go to https://webgate.ec.europa.eu/rasff-window/screen/search search for Morocco (origin), collect the notifications in the last year and generate a csv file of the output (even if you didn't collect all the notifications)",
    "task_id": "823668",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Identify the latest cybersecurity best practices for cloud computing transformation on the NIST website by navigating directly to the Cloud Computing section and summarizing the key recommendations",
    "task_id": "795554",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://www.sec.gov/Archives/edgar/data/0001876042/000119312525132755/d737521ds1a.htm and follow the prompt: Extract the financial statements from this S-1/A filing. Look for tables with titles like 'Consolidated Balance Sheets', 'Consolidated Statements of Operations', and 'Consolidated Statements of Cash Flows'.",
    "task_id": "2125188",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://www.idx.co.id/StaticData/NewsAndAnnouncement/ANNOUNCEMENTSTOCK/From_EREP/202404/e8896172d8_1ec8334461.pdf and follow the prompt: Go to the Kalbe Farma Annual Report 2023. Find the section on the Consumer Health Division. Extract the key financial data for this division, including sales, growth, and profitability. Also, look for any information on new product launches or marketing strategies in the beverage segment.",
    "task_id": "2179094",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "New provisions or amendments to the EU AI Act after June 2024, latest developments",
    "task_id": "1042431",
    "category": "Web Research"
  },
  {
    "confirmed_task": "\n    You are a helpful assistant that validates if an issue detected by an upstream system is a real issue on the website or not.\n    You will be given an issue and a website url.\n    You will need to check if the issue is a real issue on the website or not.\n    You will need to use both the text content and visual screenshots of the page to validate the issue.\n    If two products are compared, or two page previews (example: product previews in a category page) are compared and show different details, click on both to go in depth into comparing, just like a human would.\n    Basically you're doing an in-depth analysis of the error, and you're trying to find out if the issue is a real issue on the website or not.\n    You will need to return a detailed markdown report of your evaluation, and if you couldn't evaluate if the issue is a real issue or not, you should also return a reason why you couldn't evaluate it.\n    Every time, whatever happens, you should return a report at the end.\n\n    Here is the issue:\n    {\n  \"title\": \"Resolve Contradictory Read/Write Speeds Between Product Specification and User Review\",\n  \"severity\": \"low\",\n  \"status\": \"open\",\n  \"page_type\": null,\n  \"regions\": [\n    \"US\"\n  ],\n  \"platforms\": [\n    \"desktop\",\n    \"mobile\"\n  ],\n  \"description\": \"Official specs list 6700 MB/s read and 5300 MB/s write, but a highlighted user review states 6000 MB/s write and 5300 MB/s read, reversing the numbers and creating a clear factual contradiction that may mislead shoppers.\",\n  \"shortlink_url\": \"https://www.bhphotovideo.com/c/product/1871607-REG/lacie_stna4000400_4tb_rugged_ssd_pro.html\",\n  \"shortlink_title\": \"4TB Rugged SSD Pro\",\n  \"issue_rows\": [\n    {\n      \"row_type\": \"image\",\n      \"image_url\": \"https://focal-dashboard.s3.amazonaws.com/issue_creation/76ee887d-4ab2-4d4e-ae35-2dc99fab0fc1.webp\"\n    },\n    {\n      \"row_type\": \"image\",\n      \"image_url\": \"https://focal-dashboard.s3.amazonaws.com/issue_creation/f9be2621-5a73-4260-86bd-d7b8ac626056.webp\"\n    }\n  ]\n}\n\n    Here is the url to check on:\n    https://www.bhphotovideo.com/c/product/1871607-REG/lacie_stna4000400_4tb_rugged_ssd_pro.html\n    ",
    "task_id": "2357258",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "go to zillow and draft all rental listings listed by property owner in brentwood, ca put the results in a blank text document on a free notepad website",
    "task_id": "21962",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\nYou are a research assistant. Given the following search about:\n-----------------\n\"I need detailed information about Marubeni Corporation's strategic platform businesses and carbon management initiatives. Please research:\n\n1. Marubeni's definition and characteristics of \"strategic platform businesses\":\n   - Official definition from Marubeni's corporate strategy documents\n   - Core characteristics and value creation mechanisms\n   - How they differ from traditional trading company businesses\n   - Strategic importance in Marubeni's long-term vision\n\n2. Detailed examples of Marubeni's platform businesses:\n   - Power retail platform: structure, digital elements, customer base, value creation\n   - Helena agriculture platform: services offered, technology integration, market reach, business model\n   - Mobility services platform: business model, key partnerships, growth strategy\n   - Healthcare information platform: data utilization, services offered, market position\n\n3. Carbon management as a potential platform business:\n   - Industry structure analysis of carbon management sector\n   - Value creation mechanisms in carbon platform businesses\n   - Digital technology applications (especially MRV systems, blockchain)\n   - How trading companies are positioning in this space\n\n4. Carbon credit market in Asia-Pacific:\n   - Market structure, size and growth trends\n   - Japan-Australia connections and carbon trading opportunities\n   - Regulatory frameworks affecting market development\n   - Key players and competitors\n\n5. Corporate Carbon (Australian company):\n   - Business model details\n   - Projects portfolio and capabilities\n   - Leadership team and expertise\n   - Potential as foundation for carbon management platform\n   - Connection to Marubeni (if any exists)\n\n6. Carbon credit MRV (Measurement, Reporting, Verification) technologies:\n   - Latest developments in measurement technologies\n   - Reporting standards and platforms\n   - Verification methodologies\n   - Blockchain applications in carbon markets\n   - Integration of satellite/remote sensing with verification systems\"\n-----------------\nUse \"search_web\" and \"Browsing\" the web for information related to this query and produce a concise summary of the results. \nYour summary should:\n- Summary should be detailed and structured and less than 300 words.\n- Capture the main points and key information\n- Be written succinctly without unnecessary fluff\n- Focus on factual information that would be useful for a comprehensive report\n- Use the format [relevant text](URL) for inline citations\n- If exact URLs are not available, describe the source in brackets [Source: Company official website]\n\nThis summary will be used by someone synthesizing a larger report, so it's vital you capture \nthe essence of the information available online. Do not include any additional commentary \nor meta-discussion beyond the summary itself.\n\nSearch thoroughly and provide the most relevant, accurate, and up-to-date information available.\n",
    "task_id": "2090990",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Read webpage https://www.icis.com/explore/commodities/chemicals/ and follow the prompt: Navigate to the website and find information about their data and API offerings. I'm looking for details on what data is available, how it can be accessed (API, data feeds, etc.), and any developer documentation. Extract this information and save it to a file.",
    "task_id": "2307496",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://SlimSista.com and follow the prompt: Analyze the brand and style guidelines of SlimSista.com including:\n1. Color scheme and branding colors\n2. Typography and font choices\n3. Overall design aesthetic and style\n4. Layout patterns and design elements\n5. Logo and brand imagery\n6. Content structure and organization\n7. User experience patterns\n8. Any specific design elements that define the brand identity\nTake detailed notes of all visual and stylistic elements for creating an ebook that matches this brand.",
    "task_id": "2236188",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Go to Google, search golf courses Perth, and give me the contact information from the business info.",
    "task_id": "747485",
    "category": "Search Results Extracting"
  },
  {
    "confirmed_task": "Find detailed pipeline information for OmnilinX Therapeutics",
    "task_id": "485794",
    "category": "Web Research"
  },
  {
    "confirmed_task": "\n    0. Go to https://www.daraz.pk/, handle any captcha/security if shown.\n    1. Search for 'wireless headphones'.\n    2. Browse and extract product information from the first two pages.\n    3. For each product, extract:\n        - Product Name\n        - Price\n        - Number of Sold units\n    4. Identify top best-selling products.\n    5. Provide a summary table with:\n        - Product Name\n        - Price\n        - Number Sold\n    ",
    "task_id": "1485252",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "go to amazon.com, search laptops, go to each laptop page and grab info of (Name,RAM,GPU,Processor,Display,Weight,Storage,Screen_Type,Refresh_Rate,Operating_System,Color,Price,Rating,URL), do it for 2 amazon pages",
    "task_id": "122404",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "go to google.com and type 'bicentennial quarter' click search and open top 10 urls contact page and give me email id list with website url",
    "task_id": "349126",
    "category": "Search Results Extracting"
  },
  {
    "confirmed_task": "Analyze MCC token smart contract code on BSC to identify functions, ownership, and potential risks with urls or queries: ['https://bscscan.com/token/0x700735317e1af4687c17f5c30e11a74778395922#code']\n\nFor Context: Navigate to BscScan contract page for MCC token. Analyze the contract code to:\n1. Check if contract is verified\n2. Identify all READ functions and their purposes\n3. Identify all WRITE functions and analyze risks\n4. Check for mint, burn, pause, blacklist functions\n5. Analyze owner privileges and access control\n6. Look for any backdoors or suspicious code\n7. Check for proxy pattern or upgradability\nCreate an artifact file named 'mcc_bsc_contract_code_analysis.md' with detailed function analysis.",
    "task_id": "1797096",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\n    Consult the 'Breast Cancer' medical guidelines for the following case vignette:\n\n    **Case Vignette:**\n    {'age': 50, 'gender': 'F', 'pathology': 'Invasive ductal carcinoma (IDC) of the breast, Grade 3, 2.5 cm, node negative, no distant metastatic disease', 'radiology': None, 'medical_history': [], 'molecular_testing': [], 'cancer_status': {'cancer_type': 'Triple Negative Breast Cancer', 'tnm_staging': {}, 'disease_staging': 2, 'biomarker_status': [{'biomarker_name': 'ER', 'result': 'Negative', 'unit': None}, {'biomarker_name': 'PR', 'result': 'Negative', 'unit': None}, {'biomarker_name': 'HER2', 'result': 'Negative', 'unit': None}, {'biomarker_name': 'Ki-67', 'result': '75%', 'unit': None}], 'tissue_type_and_grade': 'Invasive ductal carcinoma, Grade 3'}}\n    \n**Assessed Clinical Status:**\n{\n  \"clinical_status\": \"curative_treatment\",\n  \"past_treatments\": [],\n  \"reasoning\": \"The patient is diagnosed with Invasive ductal carcinoma (IDC) of the breast, Grade 3, 2.5 cm, node negative, and no distant metastatic disease, indicating a potentially curable condition. The cancer is staged as disease_staging=2, and the patient has Triple Negative Breast Cancer with high Ki-67 (75%), suggesting an aggressive tumor. Given the absence of distant metastasis and the localized nature of the disease, the patient is likely undergoing or about to undergo curative treatment, which may include surgery and/or chemotherapy. No past treatments are mentioned.\"\n}\n**Assessed Treatment Goal:**\n{\n  \"treatment_goal\": \"curative\",\n  \"reasoning\": \"The patient is a 50-year-old female with Invasive ductal carcinoma (IDC) of the breast, Grade 3, 2.5 cm, node-negative, and no distant metastatic disease. The cancer is classified as Triple Negative Breast Cancer with a disease staging of 2. Given the patient's age, tumor size, grade, and absence of distant metastasis, the overall treatment goal is likely curative as the disease is localized and potentially resectable. The high Ki-67 (75%) indicates a high proliferation rate, but this does not change the overall curative intent of the treatment.\"\n}\n\n    Find the key recommendations from the guidelines that are most applicable given the patient's situation (including the assessed clinical status and treatment goal, if provided).\n\n    Provide references for your recommendations, including page numbers or named sections from the guideline document.\n    ",
    "task_id": "2340930",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Invesco Real Estate Investment Criteria Hospitality",
    "task_id": "410209",
    "category": "Search"
  },
  {
    "confirmed_task": "Summarize the key aspects of the latest open-source model for health record de-identification published on Hugging Face.",
    "task_id": "1833673",
    "category": "Search"
  },
  {
    "confirmed_task": "Please verify is the following reasoning correct: Multiple reputable news sources reported that the auction house Christie's suffered a ransomware-driven cyberattack in late May 2024. The attack, claimed by the RansomHub group, took Christie's website offline and resulted in the confirmed theft of client-related data. Christie's itself acknowledged the breach in official communications, stating that non-financial client data had been compromised. These articles establish a confirmed cybersecurity incident affecting Christie's within the last 12 months.Please make sure you are looking at the following company: {\"DU_NAME\":\"CHRISTIE'S B.V.\",\"SUBSIDIARY_NAME\":\"CHRISTIE'S AMSTERDAM B.V.\",\"DU_CITY\":\"AMSTERDAM\",\"DU_STATE\":\"NOORD-HOLLAND\",\"DU_COUNTRY\":\"NETHERLANDS\",\"DU_INDUSTRY\":\"Financial Services\",\"SUB_SEGMENT\":\"Banks, Insurance & asset\\/wealth managers\"}",
    "task_id": "1736651",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Read webpage https://www.ptechpartners.com/ and follow the prompt: Navigate to this website and find the About Us, Team, Leadership, or Staff pages. Extract all named contacts with their job titles and email addresses if available. Look for team member directories, executive profiles, and any contact information.",
    "task_id": "1873462",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "go to B0DQY9DY79 and look for the product price and give it to me in the results along with product name and seller.",
    "task_id": "229756",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Goal: Find detailed information about session duration settings in Google Workspace, particularly the recommended 16-hour session duration and security risks of extending it\nBackground motivation: The user wants to understand the security implications of extending Google Cloud services session duration beyond the recommended 16 hours in Google Workspace settings\nExpected output format: Detailed information about Google Workspace session duration settings, the default or recommended values, purpose of these settings, and security risks of extending session durations beyond recommended values\n\nCandidate URLs: \n- https://support.google.com/a/answer/12812005\n- https://cloud.google.com/identity/docs/how-to/session-control\n- https://workspace.google.com/security",
    "task_id": "1696154",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Create me a list of jobpostings for with Title: Salesforce Developer in the Netherlands. Retrieve the Title and Url in json format. The jobpostings can be found at https://www.linkedin.com/jobs. Skip radar pages to analyze the job postings.",
    "task_id": "1176896",
    "category": "Search Results Extracting"
  },
  {
    "confirmed_task": "Casino in El Salvador Hotel Tropico Inn San Miguel licensing regulations local laws",
    "task_id": "839625",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Goal: Get specific details about freetype module's CMake configuration and how to include it in a container build\nBackground motivation: Need to provide exact information about the dependency status of freetype in OpenCV 4.10.0 and how to include it in a container build.\nExpected output format: The exact CMake configuration showing how freetype dependency is handled, and specific instructions for including it in a container build.\n\nCandidate URLs: \n- https://github.com/opencv/opencv_contrib/blob/4.10.0/modules/freetype/CMakeLists.txt\n- https://github.com/opencv/opencv/wiki/Docker\n- https://github.com/opencv/opencv_contrib/blob/4.10.0/modules/freetype/README.md",
    "task_id": "1624674",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Go to redfin.com, handle any security checks, search for properties in San Diego, CA. Apply the following filters: Max Price set to $500,000, Bedrooms set to 3+. Since there isn't a direct 'nice view' filter, scan the listing descriptions or details of the filtered results for keywords like 'view', 'ocean', 'bay', 'panorama', 'scenic', 'hilltop'. Collect the URLs of the first 5 properties that match all these criteria (price, bedrooms, and view keywords).",
    "task_id": "1360102",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "market share of Swedish stock brokers 2023",
    "task_id": "97930",
    "category": "Search"
  },
  {
    "confirmed_task": "Scrape the first 20 tenders for UN-related IT projects from the UN Global Marketplace at https://www.ungm.org/Public/Notice",
    "task_id": "1133145",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Ruby latest version 3.3 security vulnerabilities CVE",
    "task_id": "536867",
    "category": "Search"
  },
  {
    "confirmed_task": "Goal: Find detailed information about CVE-2024-34459\nExpected output: Detailed information about CVE-2024-34459 from authoritative sources, including technical details and mitigations\n\nCandidate URLs: \n- https://nvd.nist.gov/vuln/detail/CVE-2024-34459\n- https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2024-34459",
    "task_id": "1289271",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Chromium Issue Tracker FedCM security vulnerabilities 2023 2024",
    "task_id": "1068142",
    "category": "Search"
  },
  {
    "confirmed_task": "Read webpage https://www.instagram.com/teo__idt/ and follow the prompt: Analyze this Instagram account thoroughly. I need to understand:\n1. What type of content does this account post? (photos, videos, stories, reels, etc.)\n2. What are the main themes/topics of the content? (lifestyle, business, fitness, art, etc.)\n3. What is the posting frequency pattern?\n4. Can you see any engagement metrics (likes, comments) on recent posts?\n5. What appears to be the target audience based on content style?\n6. Are there any captions or hashtags that indicate the content category?\n\nPlease provide a detailed analysis of the account's content strategy and style.",
    "task_id": "2147069",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "9th circuit forum non conveniens factors internet defamation EU citizen plaintiff",
    "task_id": "391894",
    "category": "Search"
  },
  {
    "confirmed_task": "\nYou are a research assistant. Given the following search about:\n-----------------\n\"Please continue collecting and analyzing the financial data for KCG Corporation Public Company Limited from the Stock Exchange of Thailand (SET) database and company's official website. Focus on gathering a complete 5-year dataset that includes key financial metrics, performance trends, and any relevant information for investment decision-making. Once you have completed this comprehensive analysis, please provide the detailed findings.\"\n-----------------\nUse \"search_web\" and \"Browsing\" the web for information related to this query and produce a concise summary of the results. \nYour summary should:\n- Summary should be detailed and structured and less than 300 words.\n- Capture the main points and key information\n- Be written succinctly without unnecessary fluff\n- Focus on factual information that would be useful for a comprehensive report\n- Use the format [relevant text](URL) for inline citations\n- If exact URLs are not available, describe the source in brackets [Source: Company official website]\n\nThis summary will be used by someone synthesizing a larger report, so it's vital you capture \nthe essence of the information available online. Do not include any additional commentary \nor meta-discussion beyond the summary itself.\n\nSearch thoroughly and provide the most relevant, accurate, and up-to-date information available.\n",
    "task_id": "2077285",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Important: I am a UI Automation Tester validating the tasksopen the website https://www.ford.comscroll to the bottom most and click on the Build & Price linkselect ESCAPE care in the page",
    "task_id": "1365387",
    "category": "UI Testing"
  },
  {
    "confirmed_task": "Scrape the tenders from https://www.act.nato.int/opportunities/contracting/. For each tender, extract the title, reference number, submission deadline, estimated budget, description, eligibility criteria, procedure type, and dedicated URL. Return the results as a JSON array of objects.",
    "task_id": "1145398",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\n            Find the website for All Star Roofing LinkedIn Page or use Google to search for the All Star Roofing on All Star Roofing LinkedIn Page (this method works best with non goverment websites such as linkedin).\n            Search for the company 'All Star Roofing' with context: {\"location\": \"550 Carter Ln, Smyrna TN 37167\"} using the method: Search for 'All Star Roofing' on LinkedIn. Review the company's profile page. Check employee profiles for titles and roles..\n            Extract the following attributes: owners, management, number of employees, serviceable area, company description, employee profiles, industry, company size.\n            Export all found information in structured JSON format.\n            You must include the URL you extracted the data from in the results.\n            Do not try to login to any website. You do not have credentials for any login.  \n            If at any point you get blocked by cloudflare, attempt to bypass it.  If you are unable to do so STOP.",
    "task_id": "1244960",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "go to https://marketingsummit.siliconslopes.com/agenda/list/?tribe-bar-date=2025-05-05 and open each \n        talk and extract name of the talk, description of the talk, presenter's information including name, title and company.\n        once you have the information of the presenter, open LinkedIn and search for the presenter by name & company. If found, get the linkedin\n        profile\n        ",
    "task_id": "1406205",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "You are a legal research assistant focused on California Proposition 65 cases. \n\nYour task is to search for active legal cases related to a company on the California Prop 65 case tracking website.\n\n1. Go to the California Prop 65 case search page at https://oag.ca.gov/prop65/60-day-notice-search\n2. Search for the company using its official name: Puritan in the Defendant Name field\n3. Click on the search button (which is at the bottom of the page there will be two serach button one on top and one on bottom scroll to the bottom)\n3. For each case you find, extract the following information:\n   - Case number\n   - Case title\n   - Status (e.g., active, closed, pending)\n   - Description (brief summary of what the case is about)\n   - Whether it relates to any of the products listed below\n\n4. Special attention for these products:\nPuritan's Pride Ginger Root 500 mg\n\nEvaluate whether any of the cases specifically mention these products or product categories that could include them.\n\nIMPORTANT: If the exact company name doesn't return results, you may try a portion of the name, but focus on using the provided official company name as accurately as possible.\n\nReturn your findings in the required format, even if no cases are found.\n",
    "task_id": "1563973",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Research the company 'Dashlane' and provide a summary of the company's history, products, executive team, funding rounds, contact information, social media urls, pricing data, business model, app ids, and notable achievements.",
    "task_id": "835805",
    "category": "Web Research"
  },
  {
    "confirmed_task": "\n            Find the website for New York State Department of Labor or use Google to search for the Clapper Construction LLC on New York State Department of Labor (this method works best with non goverment websites such as linkedin).\n            Search for the company 'Clapper Construction LLC' with context: {\"location\": \"211 Main St NY Otego 13825 US\"} using the method: Check the NYS Department of Labor website for information related to Clapper Construction LLC, particularly regarding workers' compensation coverage. Information access may be limited..\n            Extract the following attributes: workers' compensation insurance coverage, safety violations, employee information (potentially, if accessible).\n            Export all found information in structured JSON format.\n            You must include the URL you extracted the data from in the results.\n            Do not try to login to any website. You do not have credentials for any login.  \n            If at any point you get blocked by cloudflare, attempt to bypass it.  If you are unable to do so STOP.",
    "task_id": "1290799",
    "category": "Search"
  },
  {
    "confirmed_task": "list of stocks appearing in both FII/DII activity and MF bulk deals January 2025",
    "task_id": "437252",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Go to https://www.google.com/maps/place/UCI+Cinemas+Showville+Bari/@41.0907971,16.8850177,17z/data=!4m8!3m7!1s0x1347e9b7eab37763:0x407625fc0e2e259a!8m2!3d41.0907931!4d16.8875926!9m1!1b1!16s%2Fg%2F11b6g9l0rz?entry=ttu&g_ep=EgoyMDI1MDMwMy4wIKXMDSoASAFQAw%3D%3D and take all the reviews\n",
    "task_id": "917119",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://videogpt.io/ and follow the prompt: I need to create a 10-15 second 3D Pixar-style animated video for \"SNAKE ATTACK\" game splash screen. Please help me use this video generator to create the video with this script:\n\n\"3D Pixar animation style 15-second video: Opens with dramatic black screen, glowing neon text 'IN A WORLD... FULL OF PIXELS...' appears. Cut to pixel art jungle with rustling leaves and ominous 8-bit atmosphere. Sudden dramatic zoom to snake eye close-up - glowing red eyes with fire effects. Show tiny golden pixelated apple floating in slow motion, spinning like the Holy Grail. Pixelated snake slithers fast, slams into walls with retro neon glitch effects and explosion of colorful pixels. Snake grows longer, eyes glowing, dodging tight corners, flying through tunnels made of fruit. Epic finale: snake launches into sky like rocket, spelling out 'SNAKE ATTACK' in glowing letters with energy pulses. Ends with 'Press Start, Snack Warrior' text. Style: energetic neon retro aesthetic, dramatic cinematic lighting, vibrant colors, epic orchestral music with 8-bit chiptune elements.\"\n\nPlease create this video if the service allows it without authentication.",
    "task_id": "2061640",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Goal: Find information about security announcements at Google I/O 2025, specifically developer security tools, API security features, and Chrome/browser security improvements\nBackground motivation: Need to gather technical details about security announcements from Google I/O 2025 that would be relevant to security engineers, including developer security tools, API security features, and Chrome/browser security improvements\nExpected output format: Comprehensive technical details about security announcements at Google I/O 2025, organized by category (developer security tools, API security features, and Chrome/browser security improvements)\n\nCandidate URLs: \n- https://io.google/2025\n- https://developers.google.com/events/io\n- https://security.googleblog.com/\n- https://developer.chrome.com/blog/",
    "task_id": "1734507",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Find companies/institutes actively developing KRAS G12D-targeted therapies. For each entity:\n1. Identify the company/institute name\n2. Collect asset/drug name\n3. Determine development stage (Preclinical/Phase 1/2/3)\n4. Confirm target is KRAS G12D specifically\n5. Note indications being studied (e.g., colorectal cancer)\n6. Identify mechanism of action (e.g., inhibitor, PROTAC)\n7. Collect reference URLs from reliable sources (clinicaltrials.gov, company pipelines, peer-reviewed papers)",
    "task_id": "96275",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Go to Crunchbase or relevant aggregator sites and search for Orbital Operations to check any disclosed funding information beyond Y Combinator.",
    "task_id": "1048128",
    "category": "Search"
  },
  {
    "confirmed_task": "Go to https://www.docebo.com/customers/ and apply filters for manufacturing industry. Look through the customer stories to find Fortune 500 manufacturing companies with C-level executive quotes and ROI metrics over 200%. Extract specific quotes, company names, executive titles, and ROI figures.",
    "task_id": "2310254",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Extract all product data (name, price, url, image) from all pages of the search results on https://www.bstn.com/us_en/catalogsearch/result/?q=all&categories=Men. Navigate through the pagination until the last page and collect data from each product listed.",
    "task_id": "1625845",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Extract detailed information about the ZOTAC Gaming GeForce RTX 5080 from Amazon, including specifications, features, and customer reviews.",
    "task_id": "1528795",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://en.youlive.ca/vancouver-building/10526-cambie-garden and follow the prompt: Extract the detailed building information from this page in the exact format the user specified:\n- Building Name\n- Full Address \n- City\n- Neighbourhood  \n- For Sale (number of units)\n- Avg Price (with percentage change if shown)\n- Units / Floors\n- Year Built\n- Material\n- Developer\n- Amenities (full list)\n\nAlso analyze the page structure to understand how to systematically extract this data from similar building pages.",
    "task_id": "2092706",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Go to ycombinator.com and find all enterprises under the Winter 2025 (W25) B2B tag. Collect information such as name, description, founder(s), location, and website URL for each enterprise.",
    "task_id": "1136410",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Top U.S. technology stocks by market capitalization 2019 to 2025",
    "task_id": "1402529",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Read webpage https://www.amazon.com/s?k=rtx+3060+ti+gaming+pc+intel+i7 and follow the prompt: Extract a list of computer models with RTX 3060 Ti and Intel Core i7. For each model, extract: exact processor model, RAM amount and type, storage configuration (SSD/HDD sizes), power supply specifications, case type/size, pre-installed operating system, and price.",
    "task_id": "1672827",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://dtfprinterusa.com/ and follow the prompt: Navigate to the website and perform a technical analysis. Check for site speed, mobile optimization, crawlability (robots.txt, sitemap.xml), and identify the key money pages (homepage, product pages, category pages).",
    "task_id": "2277898",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\n        Goto the link https://apna.co/candidate/jobs. This is a job search portal.  \n\n        You have to select 2 filters.\n        \n        1. Under Filters, for Department, if there is a link saying \"Show 38 more >\",click on it and then select \"Domestic Worker\".\n        \n        2. Under Filters, for \"Date posted\", select \"Last 7 days\".\n        \n        Make sure \"Last 7 days\" and \"Domestic Worker\" filters are now showing under Filters.\n        \n        Wait for the results as per the filters.\n        \n        Click on each search result and read the job details and produce a JSON format with the following fields:\n        \n        Job ID\n        Category\n        Job Portal\n        City\n        Link\n       Company\nContact Person name\nContact person phone number\nJob Title\nMin Salary\nMax Salary\nWork Hours\nDays\nNumber of Openings\nJob Expiry Date\nPosted On\nType of Job\nBenefits\nJob Location\nMin Qualification\nExperience Range\nNo Mandatory Exp\nGender Pref\nRequirements\nInfo  \n\n    Try to guess the value of each field from the page content. For Job ID, use the last part of the URL and for Link, use the full URL.\n     \n    Go back to the search results page and repeat the process for the remaining results.\n    \n    Write all the results in a file called output.json\n        \n\n        ",
    "task_id": "1310325",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Carikan saya undang undang di indonesia yang mengatur seputar kebijakan proteksi data di perusahaan, dan jelaskan pasal berapa dan maknanya apa",
    "task_id": "490126",
    "category": "Web Research"
  },
  {
    "confirmed_task": "\n        **Task:** Perform a comprehensive web search for the stock symbol **RELIANCE.NS** focusing on the last 6 months.\n\n        **Information to find:**\n        1.  **Earnings Reports:** Dates and key highlights/summaries of the last 2 quarterly earnings reports. Check official sources like BSE India (www.bseindia.com) filings or reliable financial news sites.\n        2.  **Major News & Announcements:** Significant company news (product launches, M&A, partnerships, management changes, regulatory issues).\n        3.  **Analyst Ratings:** Recent changes in analyst ratings or price targets.\n        4.  **Fundamental Events:** Any other major fundamental events impacting the stock price or outlook.\n\n        **Instructions:**\n        - Search reputable financial news websites (e.g., Bloomberg Quint, Moneycontrol, Economic Times, Reuters, official company website, BSE India).\n        - Synthesize the findings into a concise summary focusing on the most impactful information from the last 6 months relevant to an investment decision.\n        - Structure the output clearly. Use bullet points for key findings under headings like \"Recent Earnings\", \"Key News\", \"Analyst Actions\".\n        - The summary should be neutral and factual.\n\n        **Output Format:** Generate ONLY the summary text (in Markdown if possible). Do not include conversational text or explanations outside the summary itself.\n        ",
    "task_id": "1473802",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Visit https://mailchimp.com/pricing/marketing/compare-plans/?currency=EUR and analyze the pricing information.\n                \n                1. Extract all pricing plans/tiers\n                2. For each tier collect:\n                   - Name\n                   - Monthly price\n                   - Description\n                   - Special messages\n                   - the selected contact number\n                   - Maximum subscribers limit\n                \n                3. Check pricing modifiers:\n                   - Contact selectors\n                   - Sliders\n                   - Dropdowns\n                \n                4. Test different contact numbers:\n                   - 1000 contacts\n                   - 5000 contacts\n                   - 10000 contacts",
    "task_id": "839951",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\n    Go to https://www.dextools.io/app/en/ether/pool-explorer.\n    Observe the list of newly listed token pairs.\n    Focus on pairs listed within the last 15 minutes.\n    For each such token pair that meets the criteria (liquidity > 50 ETH and age < 15 minutes):\n        1. Extract the token name (e.g., \"MyToken\", not the pair like \"MyToken/WETH\").\n        2. Extract the token's contract address.\n        3. Extract the liquidity in ETH. Convert this to a float.\n        4. Extract the listing age in minutes. Convert this to an int.\n    Compile this information into a list of Python dictionaries. Each dictionary should have keys:\n    'name' (str), 'contract_address' (str), 'liquidity_eth' (float), 'age_minutes' (int).\n    Return this list of dictionaries as a Python-parsable string.\n    For example: \"[{'name': 'TokenA', 'contract_address': '0x123...', 'liquidity_eth': 60.0, 'age_minutes': 10}, ...]\"\n    If no tokens meet the criteria, return an empty list \"[]\".\n    ",
    "task_id": "1656949",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "OPEC crude oil production data February 2025",
    "task_id": "851032",
    "category": "Search"
  },
  {
    "confirmed_task": "Look for the most current quantum computing research papers sent to ArXiv over the past two days.",
    "task_id": "1125412",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\n        Visit https://breaking-bet.com/en/arbs/prematch\n\n        1. Look for the gear/settings icon in the TOP RIGHT corner of the page (it's a circular icon with a gear symbol).\n           This is the filter button. Click on it.\n\n        2. In the filter panel that opens:\n           - First, find and click the \"Select None\" button to uncheck all bookmakers\n           - Then find and check ONLY these specific bookmakers: 1xbet, bet9ja, merrybet, nairabet, betking, melbet\n           - Click the Apply button to apply the filter\n\n        3. If there's a \"show all\" link at the bottom of the opportunities list, click it to see all opportunities.\n\n        4. For each opportunity row, extract:\n           - Profit percentage (e.g., \"0.02%\", \"0.66%\")\n           - Sport type (e.g., \"Basketball\", \"Handball\")\n           - Event details (teams/participants)\n           - Both bookmaker names (e.g., \"SportyBet\", \"NairaBet\")\n           - Bookmaker links (extract href attributes)\n           - Odds values (e.g., \"1.91\", \"2.1\")\n           - Market type (e.g., \"TO\", \"TU\", \"X2\")\n\n        Structure the data in JSON format with these fields:\n        - profit_margin: the profit percentage as a number\n        - sport_type: the sport (e.g., \"Basketball\")\n        - league: the competition name (e.g., \"Euroleague\")\n        - event: the match description (e.g., \"Maccabi Tel-Aviv - Panathinaikos BC\")\n        - market: the bet market type (e.g., \"TO\", \"TU\")\n        - bookmaker1: first bookmaker name\n        - bookmaker1_link: link to first bookmaker\n        - team1: first team/selection\n        - odds1: odds for first selection\n        - bet1: bet type for first selection (e.g., \"TO(171.5)\")\n        - bookmaker2: second bookmaker name\n        - bookmaker2_link: link to second bookmaker\n        - team2: second team/selection\n        - odds2: odds for second selection\n        - bet2: bet type for second selection (e.g., \"TU(171.5)\")\n        \n        Return the data as a JSON array.\n        ",
    "task_id": "1123218",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Go to https://www.similarweb.com/website/\nAnalyze traffic for the website https://revapets.com\nClick the analyze traffic button and wait for the load of the data\nGive me the below info on the website\n- Year Founded\n- Global Rank\n- Total Visits\n- Bounce Rate\n- Pages per Visit\n- Avg Visit Duration\n- Trending of Total Visits Last 3 Months\n- Top Countries\n- Website Traffic Demographics\n- organic search\n- paid search\n\nThe output return in JSON format ",
    "task_id": "1026443",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Nvidia insider trading recent SEC filings",
    "task_id": "89728",
    "category": "Search"
  },
  {
    "confirmed_task": "tell me all the details about renile startup from crunchbase and its investors, and how much funding they have raised",
    "task_id": "1225015",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Find more information about the companies listed in the Dementia Discovery Fund portfolio, including their therapeutic focus, pipeline, stage of development, and therapeutic modality.",
    "task_id": "482850",
    "category": "Web Research"
  },
  {
    "confirmed_task": "PROMPT - Generate a script to extract all countries and their most recent year and value for electricity access from this url, such that it adheres to the given output schema. It should be robust and handle edge cases. This data will be updated every month, so I need a script to run every month to get the most recent data.\nURL - https://data.worldbank.org/indicator/EG.ELC.ACCS.ZS?name_desc=false\nSCHEMA - {'Country': 'string', 'Most Recent Year': 'integer', 'Most Recent Value': 'float'}",
    "task_id": "966617",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Show the \"Sony WH-1000XM5 headphones\" offers in order of price from lowest to highest.",
    "task_id": "2169664",
    "category": "Price Scraping"
  },
  {
    "confirmed_task": "Read webpage https://www.vals.ai/benchmarks and follow the prompt: \\u68c0\\u67e5\\u6240\\u6709\\u7684\\u57fa\\u51c6\\u6d4b\\u8bd5\\u9875\\u9762\\uff0c\\u83b7\\u53d6\\u5404\\u4e2a\\u6a21\\u578b\\u5728\\u4e0d\\u540c\\u57fa\\u51c6\\u6d4b\\u8bd5\\u4e0a\\u7684\\u6027\\u80fd\\u6570\\u636e\\uff0c\\u7279\\u522b\\u662f\\u6587\\u4ef6\\u4e2d\\u63d0\\u5230\\u7684\\u6a21\\u578b\\uff08\\u5982GPT-4o\\u3001Claude-3.7-Sonnet\\u3001Gemini-2.5-Pro-Exp\\u3001Deepseek-R1\\u3001QwQ-32B\\u7b49\\uff09\\u5728MMLU\\u3001HumanEval\\u3001GSM8K\\u3001C-Eval\\u7b49\\u6d4b\\u8bd5\\u4e0a\\u7684\\u8868\\u73b0",
    "task_id": "1757675",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://www.beauhurst.com/ and follow the prompt: Extract detailed information about Beauhurst database capabilities including what UK company data fields are available, revenue and funding information access, API availability, data access methods, and how comprehensive the database is for UK private companies.",
    "task_id": "2094857",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Go to google search and serch for keyword \"Best dentist in texas\" then go to 2nd page and see all the website that rank and then go to the contact page and give me there email and contact details in tabel form ",
    "task_id": "347830",
    "category": "Search Results Extracting"
  },
  {
    "confirmed_task": "Read webpage https://www.spitexcare.ch/ and follow the prompt: Analyze the website spitexcare.ch to understand their local SEO strategy. Look for location-specific landing pages, local keyword usage, local contact information, and local testimonials. Document your findings.",
    "task_id": "2140824",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\n        **Task: Scrape Amazon Electronics (Output must be valid Python dict or list of dicts)**\n\n        **Steps:**\n        1. Open Amazon.com in the browser\n        2. Search for \"Electronics\"\n        3. Open the first item\n        4. Return the scraped details as dict, e.g.:\n           {\n             \"name\": \"Example Product\",\n             \"shop_name\": \"Example Store\",\n             \"rating\": \"4.5\",\n             \"reviews\": \"10,234\",\n             \"description\": \"...\",\n             \"url\": \"https://...\"\n           }\n        ",
    "task_id": "382924",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Search for jobs matching these criteria:\n- Keywords: Crew AI, Cursor, AI Builder, Prompt Engineering\n- Locations: North America\n\n- Minimum salary: 140000\n- Remote only: False\n\nSearch across multiple job boards (Indeed, Glassdoor, etc.) in separate tabs. Collect detailed information about each position including requirements and full descriptions. Avoid LinkedIn. After collecting the data, display a summary and save detailed information to a file.",
    "task_id": "128",
    "category": "Search"
  },
  {
    "confirmed_task": "Read webpage https://derma-solution.com/ and follow the prompt: Analyze this second competitor's website homepage for complete SEO competitive analysis. Extract and document:\n\n1. Page Structure & Content:\n   - Page title, meta description, headings\n   - Content sections and organization\n   - Product positioning and categories\n   - Brand messaging and USPs\n\n2. SEO Approach:\n   - Keyword strategy and targeting\n   - Technical SEO elements\n   - Content optimization\n   - Site architecture\n\n3. Competitive Positioning:\n   - How they differentiate from other Korean beauty suppliers\n   - Trust and credibility elements\n   - Unique value propositions\n\n4. SEO Benchmarking:\n   - Strengths that upkeepskin.com should consider\n   - Weaknesses that present opportunities\n   - Best practices to adopt\n\nThis will complete our competitive analysis for comprehensive SEO recommendations.",
    "task_id": "2216354",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "I need you to go to google maps, type montreal , then type pizza to find pizza in Montreal then check all restaurants and find those with less than 6 reviews. extract their informations",
    "task_id": "107741",
    "category": "Search Results Extracting"
  },
  {
    "confirmed_task": "Read webpage https://medium.com/@nambos3rd/tesla-full-year-2024-analysis-a-review-of-actual-performance-my-financial-forecast-41ee70091b5a and follow the prompt: Extract comprehensive Tesla 2024 full year financial analysis including revenue trends, profit margins over time, cash flow analysis, balance sheet highlights, and key financial ratios. Focus on historical data and trends over multiple years.",
    "task_id": "1785321",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Infer using tool [infer_from_page_markdown_with_navigational_links]- extract articles (with corresponding navigational URL) that mentions opening of international luxury retail brands in Singapore. \n            Do this for subsequent pages and only consider articles that appear sequentially before article:'Snake and red jewels make fortuitous symbols this Lunar New Year'.\n            Finish condition: after the page containing 'Snake and red jewels make fortuitous symbols this Lunar New Year' has been processed and relevant articles extracted.",
    "task_id": "1377055",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://www.mordorintelligence.com/zh-CN/industry-reports/smart-sound-and-gateway-market and follow the prompt: \\u63d0\\u53d6\\u6587\\u7ae0\\u4e2d\\u5173\\u4e8e\\u667a\\u80fd\\u58f0\\u97f3\\u4ea7\\u54c1\\u5e02\\u573a\\u89c4\\u6a21\\u3001\\u589e\\u957f\\u8d8b\\u52bf\\u3001\\u5e02\\u573a\\u5206\\u5e03\\u3001\\u7ade\\u4e89\\u683c\\u5c40\\u4ee5\\u53ca\\u672a\\u6765\\u53d1\\u5c55\\u65b9\\u5411\\u7684\\u5185\\u5bb9\\u3002\\u91cd\\u70b9\\u5173\\u6ce8\\u4e0d\\u540c\\u7c7b\\u578b\\u58f0\\u97f3\\u4ea7\\u54c1\\u7684\\u5e02\\u573a\\u8868\\u73b0\\u53ca\\u5546\\u4e1a\\u4ef7\\u503c\\u3002",
    "task_id": "1612534",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://www.europages.co.uk/companies/distributor/import-export%20-%20medical%20and%20surgical%20equipment.html and follow the prompt: Extract information about medical and surgical equipment distributors, focusing on those that distribute surgical disposables like gowns, drapes, and procedure trays. Collect company names, websites, email addresses (if available), and countries. Try to browse through multiple pages if available to collect as many relevant companies as possible. Focus only on European countries.",
    "task_id": "1716501",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "*\"Search official NSERC portals and Canadian government grant databases to identify the top 3 NSERC grants related to STEM category currently open for applications in 2025, ranked by total funding amount. For each grant, extract:  \n1. **Name**  \n2. **Total funding available** (specify if annual or total)  \n3. **Application deadline**  \n4. **Eligibility criteria**  \n5. **Key objectives**  \n6. **Link to official guidelines**  \nPrioritize grants with the highest funding ceilings and verify their open status using the most recent updates. Exclude expired or closed opportunities.\"*",
    "task_id": "1188573",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Search for each of the following networking components on a single website that provides pricing in AUD. For each product, return the vendor page link, price per unit, quantity, and total price in a structured table format.\n\nProducts List:\nDream Machine Pro Max\nPro 24 PoE\nU6 Long-Range\n12U Rack Cabinet\nPower Backup\nPower Distribution Pro\nUniFi Indoor Cable Cat6 CMP\nDirect Attach Cable (0.5m / 1.6ft, 10G)\nSmartPower Cable (Quantity: 2)\nTable Format:\nComponent Specification\tVendor (Product Page)\tPrice p/ unit (AUD)\tQuantity\tTotal (AUD)\nDream Machine Pro Max\t[Product Link]\t$XXX.XX\t1\t$XXX.XX\nPro 24 PoE\t[Product Link]\t$XXX.XX\t1\t$XXX.XX\n...\t...\t...\t...\t...\nRequirements:\n\nEnsure all prices are in AUD.\nReturn a direct link to the vendor's product page.\nIf an item is unavailable, indicate it in the table.\nEnsure accuracy in pricing and availability.",
    "task_id": "176560",
    "category": "Price Scraping"
  },
  {
    "confirmed_task": "Open the https://studio.exfdigital.com/ \n                ### **Strictly Enforced Steps for Full Website Audit**  \n\n                1. **Comprehensive Website Scan:**  \n                - Systematically navigate **every page** and ensure all sections are covered.  \n                - No page should be skipped or left untested.  \n\n                2. **Unique Click Testing:**  \n                - Click **every button, link, or interactive element** **only once** to avoid redundant checks.  \n                - If the same button appears multiple times, test only the first instance.  \n\n                3. **Handling Redirects:**  \n                - If clicking a button redirects to another page, **wait for the page to load fully**.  \n                - **Immediately close the page** after it loads, then return to continue testing.  \n\n                4. **Error Page Detection & Logging:**  \n                - If a button leads to an **error page (e.g., 503, 404, etc.)**:  \n                    - **Allow the error page to load completely.**  \n                    - **Record the button label and the exact URL that triggered the error.**  \n                    - **Close the error page to prevent repeated visits.**  \n\n                5. **Strict Error & Navigation Tracking:**  \n                - Maintain a **detailed log** of every button tested, its action, and the results.  \n                - **Ensure the audit does not revisit previously tested elements.**  \n                - **Log all failed interactions, unresponsive buttons, and broken links.**  \n\n                6. **Final Verification:**  \n                - Cross-check logs to confirm **all elements** have been tested.  \n                - print as json log of  **comprehensive report** summarizing working and non-working buttons/links.",
    "task_id": "851914",
    "category": "UI Testing"
  },
  {
    "confirmed_task": "\n                    Visit https://saytool.com/product/%EC%97%90%EC%9D%B4%EC%95%A4%EB%94%94-%EC%A0%84%EC%9E%90%EC%A0%80%EC%9A%B8%EC%A4%91%EB%9F%89%EB%B9%84%EA%B5%90-hc-30kw-hc-30kw-30kg5g/59643/\n                    If there is data corresponding to the following, please create it:\n                    Product name (prod_name), Product specifications (prod_spec), Product description (prod_desc), Model name or Model ID (model_nm), Company (company)\n                        \n                    Please provide the answer in JSON format.\n                    JSON format:\n                    {\n                        \"prod_name\": \"\",\n                        \"prod_spec\": \"\",\n                        \"prod_desc\": \"\",\n                        \"model_nm\": \"\",\n                        \"company\": \"\"\n                    }\n                ",
    "task_id": "191779",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\n        You are an e-commerce site analyzer. Visit https://www.closed.com/en/women/jeans and carefully analyze the page structure.\n        \n        1. FIRST, detect and handle any popups or consent notices that might interfere with analysis.\n        2. Analyze the product containers on the page. Identify which selectors contain products.\n        3. Extract details from 3-5 sample products using the best selector you found to verify.\n        4. Examine how pagination works - check for numbered pagination, load more buttons, or infinite scroll.\n        5. Test the pagination method to verify it works.\n        \n        Organize your findings in a detailed report focusing on:\n        - Any popups detected and how to close them\n        - Product container selectors that work best for extraction\n        - Product data structure (title, price, image, link patterns)\n        - Pagination mechanism and specific selectors needed to navigate through products\n        ",
    "task_id": "1062848",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Navigate to GitHub and search for browser automation repositories sorted by stars. Check at least the top 100 repositories. Extract and describe the top 50 repositories based on their star count. Provide their descriptions, functionalities, and key features. Conclude with an analysis of which repository you consider the best for browser automation and justify your choice.",
    "task_id": "611568",
    "category": "Search Results Extracting"
  },
  {
    "confirmed_task": "Navigate to vividseats.com and search for Toronto FC vs Inter Miami CF tickets for September 27, 2025. Extract all available ticket sections with their prices, quantities if shown, and any fees. List all sections with complete pricing information.",
    "task_id": "702654",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Please verify is the following reasoning correct: Multiple reputable sources in May 2025 report that Pearson (parent of Pearson Netherlands B.V.) suffered confirmed cybersecurity incidents, including unauthorized access to systems, data theft and customer data breaches. These include an independently reported cyberattack, a confirmed customer data breach and official notices from Pearson plc acknowledging unauthorized system access. All occurred within the last 12 months.Please make sure you are looking at the following company: {\"DU_NAME\":\"PEARSON NETHERLANDS B.V.\",\"SUBSIDIARY_NAME\":\"PEARSON BENELUX B.V.\",\"DU_CITY\":\"AMSTERDAM\",\"DU_STATE\":\"NOORD-HOLLAND\",\"DU_COUNTRY\":\"NETHERLANDS\",\"DU_INDUSTRY\":\"Financial Services\",\"SUB_SEGMENT\":\"Banks, Insurance & asset\\/wealth managers\"}",
    "task_id": "1728810",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Find the therapeutic target of the investigational drug ABBV-291. Look at the official company pipeline, conference presentations, and publications, and industry news, e.g. endpoints or biocentury.\n\nReturn a JSON object with the following format:\n{\n      \"target\": \"TargetName\",\n      \"evidence_target\": \"EXACT copied text from source [URL]\"\n}",
    "task_id": "861566",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Extract key points from the article at https://finance.yahoo.com/quote/AAPL/news/ focusing on Apple's market position, stock performance, future predictions, and any significant events or analyses.",
    "task_id": "1017491",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Google Chrome vulnerabilities CVE 2024 last two months",
    "task_id": "536815",
    "category": "Search"
  },
  {
    "confirmed_task": "Go to nasdaq.com and search for the stock symbol 'Garrett Advancing Motion'. Navigate to its historical data section and download the full-year data for 2024, if available.",
    "task_id": "959652",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://embracetransitioncoaching.com/about-paula/ and follow the prompt: Extract all content from this page including headings, text about Paula, her background, experience, coaching approach, and any other relevant information that would be useful for creating a new website",
    "task_id": "2282208",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://www.padmapper.com/apartments/san-francisco-ca and follow the prompt: Analyze the technical structure of PadMapper for San Francisco apartments. Identify: 1) How data is loaded (server-side vs JavaScript), 2) URL patterns for filtering apartments under $2000, 3) Available data fields and formats, 4) Any visible API endpoints or data loading mechanisms, 5) Anti-scraping measures like rate limiting or captchas, 6) Map integration and data source",
    "task_id": "1822100",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "site:agrieuro.co.uk \"charcoal grill\" 20-300 EUR reviews specifications Edilmark OR Classe OR Mastercook OR Royal Food OR Famur OR Ferraboli OR Seven Italy OR Palazzetti OR Cruccolini",
    "task_id": "795094",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://aiindex.stanford.edu/report/ and follow the prompt: Extract key findings from the latest Stanford AI Index report regarding China's position in AI talent, investment, research publications, model development, and government strategy compared to the US. Focus on sections comparing US and China AI metrics.",
    "task_id": "1421359",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Jackpot Plaza Aeropuerto Mexico location accessibility data, gaming laws & licensing, historical renovations, amenities services, user reviews",
    "task_id": "828136",
    "category": "Web Research"
  },
  {
    "confirmed_task": "\n        Browse a retailer's website of https://www.thiscorner.co/ and get all products the retailer carries.\n\n        For each product, capture the following details:\n        - Product name: EXACT product name as displayed on the website\n        - Product description: EXACT product description as displayed on the website (including materials, features, benefits, dimensions, etc.). \n        - Brand name: EXACT brand name as displayed on the website. \n        - Price: EXACT price as displayed on the website. \n        - Image URLs: a list of image URLs related to the product. \n\n        NAVIGATION STRATEGY:\n        - IMMEDIATELY look for navigation elements with these high-value keywords: \"Shop\", \"Products\", \"Catalog\", \"Collections\", \"Brands\"\n        - Be methodical in checking \"Brands\" pages, navigation menus, filters, product pages, footers      \n        - Do not summarize or condense product listings - include each individual product you find\n        - If there are too many products (e.g., over 500), try to sample the products from different categories, collections, or types\n        - Prioritize variety over quantity to represent the full range of offerings\n        - If there are too many product pages, try to sample the products from different product pages and for each product page, only scrape the first screen without scrolling down            \n        - If you cannot find any products, return an empty list.\n        ",
    "task_id": "1246927",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Goal: Find detailed information about CVE-2023-39417 including affected software, vulnerability type, attack vectors, and exploitation conditions\nBackground motivation: The user is requesting comprehensive information about a specific CVE (Common Vulnerabilities and Exposures) identifier CVE-2023-39417. This requires searching cybersecurity databases, vulnerability disclosure sites, and security advisories to gather technical details about the vulnerability.\nExpected output format: Detailed technical information about the CVE including affected software/library, vulnerability description, CVSS score, attack vectors, exploitation conditions, and remediation recommendations with proper citations\n\nCandidate URLs: \n- https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-39417\n- https://nvd.nist.gov/vuln/detail/CVE-2023-39417\n- https://www.cvedetails.com/cve/CVE-2023-39417/",
    "task_id": "2331277",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Goal: Find detailed information about user rights, security measures, consent mechanisms, third-party data sharing, and international data transfer protections specifically for Azure Active Directory Premium P1\nBackground motivation: Need to complete the privacy review for Azure AD Premium P1 by finding information about user control mechanisms, data subject rights (access, deletion, portability), security measures protecting personal data, third-party sharing practices, and international data transfer safeguards\nExpected output format: Detailed privacy information with direct quotes and citations focusing on user rights (GDPR compliance), security measures, consent mechanisms, third-party sharing policies, and international data transfer protections for Azure AD Premium P1\n\nCandidate URLs: \n- https://docs.microsoft.com/en-us/azure/active-directory/fundamentals/active-directory-data-storage-australia\n- https://learn.microsoft.com/en-us/azure/active-directory/fundamentals/gdpr-data-protection-privacy\n- https://www.microsoft.com/en-us/trust-center/privacy/gdpr-overview\n- https://learn.microsoft.com/en-us/azure/active-directory/enterprise-users/users-close-account\n- https://docs.microsoft.com/en-us/microsoft-365/compliance/gdpr-data-subject-requests\n- https://learn.microsoft.com/en-us/azure/security/fundamentals/protection-customer-data",
    "task_id": "2331060",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Find the components that make up ServiceTitan's revenue mix across different products and services.",
    "task_id": "2061133",
    "category": "Web Research"
  },
  {
    "confirmed_task": "\n        You are a SEO expert looking for backlinks for a website.\n        Go to google and search for banklinks for https://www.leafly.com/, exclude backlinks from social media sites.\n        Go to page 2 and 3 if needed.\n        Return the data in a structured format that matches the BacklinkSearchResult model.",
    "task_id": "1009379",
    "category": "Search Results Extracting"
  },
  {
    "confirmed_task": "Coeur d'Alene Casino in United States legal requirements and licensing details",
    "task_id": "833683",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Go to https://wro.westchesterclerk.com/landsearch.aspx, Look for land records for the Name Seven Springs LLC. For each of the resulting records, collect all details. Return a valid JSON of all records",
    "task_id": "759493",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Start:\nOpen a browser and navigate to `google.com`.\nCookie Handling:\nBefore proceeding, check for a \"Reject All\" or \"Decline All\" button for cookies. If present, click it to dismiss the cookie popup. If no such button exists, use a \"Save\" or \"Confirm\" option with minimal permissions.\nSearch:\nIn the Google search bar, type \"small to medium estate agents contact information site:*.uk -inurl:(login)\" and press Enter to filter for UK-based estate agents and exclude login pages.\nPopup Check:\nAfter the search results load, check for any cookie or consent popups. If one appears, click \"Reject All\" or equivalent to dismiss it.\nAnalyze Page 1:\nScroll down incrementally, collecting contact information (e.g., phone numbers, email addresses) and business details (e.g., company name, location, owner names if available) from visible search result snippets and linked website previews.\nCheck for popups after each scroll and dismiss them if they appear.\nStop scrolling when the \"Next\" button becomes visible at the bottom of Page 1.\nProceed to Page 2:\nCheck for popups and dismiss them before clicking \"Next.\"\nClick the \"Next\" button to load Page 2.\nAnalyze Page 2:\nScroll down incrementally, collecting the same information as in Step 5.\nStop scrolling when the \"Next\" button becomes visible.\nProceed to Page 3:\nCheck for popups and dismiss them before clicking \"Next.\"\nClick \"Next\" to load Page 3.\nAnalyze Page 3:\nScroll down incrementally, collecting the same information.\nStop scrolling when the \"Next\" button becomes visible.\nProceed to Page 4:\nCheck for popups and dismiss them before clicking \"Next.\"\nClick \"Next\" to load Page 4.\nAnalyze Page 4:\nScroll down incrementally, collecting the same information.\nStop scrolling when the \"Next\" button becomes visible.\nProceed to Page 5:\nCheck for popups and dismiss them before clicking \"Next.\"\nClick \"Next\" to load Page 5.\nAnalyze Page 5:\nScroll down incrementally, collecting the same information.\nStop scrolling when you reach the end of the visible results or pagination controls (e.g., no further \"Next\" button or a clear end).\nLinkedIn Check:\nPerform a secondary Google search with \"site:linkedin.com small to medium estate agents uk\" to scan snippets for additional contact or owner information without opening LinkedIn links.\nScroll through these results on one page, stopping when no new relevant data appears.\nCompile Findings:\nOrganize your findings by page (Page 1, Page 2, Page 3, Page 4, Page 5, LinkedIn Check).\nFor each page, list estate agent names, contact details, business locations, and owner names (if identified).\nConsolidate duplicate entries across pages into a single entry with combined details.\nFinal Check: Ensure no irrelevant data (e.g., ads, unrelated businesses) is included in your summary.\nReport: Present your findings in a concise format, labeled by page (e.g., \"Page 1 Findings\"), followed by an overall summary of unique estate agents and their details.",
    "task_id": "981033",
    "category": "Search Results Extracting"
  },
  {
    "confirmed_task": "\n            Find the website for Otsego County Clerk's Office or use Google to search for the Clapper Construction LLC on Otsego County Clerk's Office (this method works best with non goverment websites such as linkedin).\n            Search for the company 'Clapper Construction LLC' with context: {\"location\": \"211 Main St NY Otego 13825 US\"} using the method: Contact the Otsego County Clerk's Office (or check their online records, if available) and search for filings under \"Clapper Construction LLC\" or the names of known principals associated with the company.  This may reveal property ownership or other business dealings..\n            Extract the following attributes: property records, business certificates, mortgages, legal filings related to the company or its principals.\n            Export all found information in structured JSON format.\n            You must include the URL you extracted the data from in the results.\n            Do not try to login to any website. You do not have credentials for any login.  \n            If at any point you get blocked by cloudflare, attempt to bypass it.  If you are unable to do so STOP.",
    "task_id": "1290796",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "{\"instructions\":{\"data_to_collect\":{\"property_info\":[\"property_name\",\"management_email\",\"phone_number\"],\"reviews\":{\"count\":2,\"details\":[\"comment_text\",\"rating\",\"date\"]},\"unit_details\":[\"available_units\",\"price_range\",\"bedroom_count\",\"bathroom_count\",\"square_footage\"]},\"sample_count\":2,\"url\":\"https://www.apartments.com/apartments/arlington-tx/min-1-bedrooms/\"},\"output_format\":{\"structure\":{\"properties\":[{\"contact\":{\"email\":\"string\",\"phone\":\"string (XXX-XXX-XXXX)\"},\"name\":\"string\",\"reviews\":[{\"date\":\"string (MM/DD/YYYY)\",\"rating\":\"number\",\"text\":\"string\"}],\"units\":[{\"availability\":\"number\",\"bathrooms\":\"number\",\"bedrooms\":\"number\",\"price\":\"number\",\"square_feet\":\"number\"}]}]},\"type\":\"json\"}}",
    "task_id": "251101",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Find specific pricing details for ServiceTitan from their official site or a trusted review site.",
    "task_id": "2213419",
    "category": "Price Scraping"
  },
  {
    "confirmed_task": "Read webpage https://bstock.com/amazon/ and follow the prompt: Navigate to the B-Stock website and find the Amazon Liquidation Auctions. I am interested in auctions for 'Toys & Games' and 'Health & Beauty' pallets. Please extract information on any currently available pallets in these categories, including the product descriptions, estimated quantity, current bid, and a link to the auction.",
    "task_id": "2214895",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\nYou are a research assistant. Given the following search about:\n-----------------\n\"Research the acquisition of Vantage Discovery by Shopify. Focus on:\n1. Verify the acquisition date (April 2025) mentioned in the emails\n2. Find official announcements or press releases about the acquisition\n3. Research the acquisition value of $100 million mentioned in the emails\n4. Gather information about Vantage Discovery's business and why Shopify acquired them\n5. Find information about Future Positive's investment history in Vantage Discovery (seed round in June 2023 and Series A 10 months later)\n6. Research Shopify's M&A strategy and how this fits their business objectives\"\n-----------------\nUse \"search_web\" and \"Browsing\" the web for information related to this query and produce a concise summary of the results. \nYour summary should:\n- Summary should be detailed and structured and less than 300 words.\n- Capture the main points and key information\n- Be written succinctly without unnecessary fluff\n- Focus on factual information that would be useful for a comprehensive report\n- Use the format [relevant text](URL) for inline citations\n- If exact URLs are not available, describe the source in brackets [Source: Company official website]\n\nThis summary will be used by someone synthesizing a larger report, so it's vital you capture \nthe essence of the information available online. Do not include any additional commentary \nor meta-discussion beyond the summary itself.\n\nSearch thoroughly and provide the most relevant, accurate, and up-to-date information available.\n",
    "task_id": "1719088",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Find the cheapest rtx5090 for sale in the netherlands. restrict your search to .nl tld sites  Is there are non currently for sale, find out where and when they will be",
    "task_id": "25308",
    "category": "Price Scraping"
  },
  {
    "confirmed_task": "Goal: Find detailed information about libfreetype6 version in Ubuntu 22.04 and comprehensive details about CVE-2025-27363\nBackground motivation: Need more specific details about when the vulnerability was fixed in Ubuntu 22.04's libfreetype6 package and the nature of the vulnerability\nExpected output format: Detailed version history of libfreetype6 in Ubuntu 22.04, when the fix for CVE-2025-27363 was applied, and technical details about the vulnerability\n\nCandidate URLs: \n- https://packages.ubuntu.com/jammy/libfreetype6\n- https://ubuntu.com/security/CVE-2025-27363\n- https://launchpad.net/ubuntu/+source/freetype\n- https://people.canonical.com/~ubuntu-security/cve/2025/CVE-2025-27363.html",
    "task_id": "1624560",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Research how to generate service account or machine authentication JWT tokens with Supabase without manually creating JWT tokens. Find official Supabase methods, API endpoints for non-interactive authentication, service roles, or machine/service account authentication patterns. Specifically look for ways to create long-lived tokens for kiosk or machine authentication through official Supabase APIs.",
    "task_id": "608738",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Read webpage https://www.poweradspy.com/ and follow the prompt: Extract exact pricing plans, features, platform coverage (Meta, Google, TikTok), performance metrics available (ROI, CTR, CPC), integrations, unique features, trial offers, and data freshness. Focus on technical specifications and current pricing for 2025.",
    "task_id": "1783199",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Cross-verify NVIDIA's recent quarterly earnings report key financial figures and forward-looking statements by checking Bloomberg News for NVIDIA earnings news and summary. Confirm consistency in reported revenue, net income, EPS, and guidance.",
    "task_id": "657655",
    "category": "Web Research"
  },
  {
    "confirmed_task": "\n        You are an AI agent specialized in finding tenders across various tender platforms such as GeM (Government e-Marketplace), MP Tenders, MP Forest Department Tenders, and other relevant sources, not many more just other main ones .\n\n        Your task is to:\n\n        Search and list active tenders that match any of the following categories:\n\n        Drone\n\n        Trap Camera\n\n        Fire Protection Kit & Items\n\n        Fire Safety Devices\n\n        Computer Peripherals (e.g., printers, keyboards, storage devices, etc.)\n\n        Requirements:\n\n        Include the tender title, tender ID/reference number, issuing authority/department, platform (e.g., GeM, MP Tenders), due date, and a brief description.\n\n        Prioritize tenders from Madhya Pradesh (MP) but include others if relevant.\n\n        Ensure the data is recent and tenders are currently open for bidding and give me all tenders detail ",
    "task_id": "1363479",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Search for Metformin on goodrx.com:\n        1. First scroll down and enter location: 172 S Sunnyvale Avenue, Sunnyvale, CA 94086\n        2. Search for Metformin\n        3. Collect the following information:\n           - Available dosage forms and strengths\n           - Prices at different pharmacies nearby\n           - Any available coupons or discount programs\n           - Generic vs brand name options\n           - Common side effects and warnings\n           - Any other relevant information\n        4. Sort results by lowest price",
    "task_id": "265277",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\nGo to https://www.bseindia.com/corporates/ann.html.\nClick the button with selector \"#btnSubmit\".\nWait until the table of announcements appears.\n\nOnly on this page, for each annoucement in the table displayed,\n- Click on XBRL link. This will opne a new tab. Extract the following information from the tab: \n ScripCode,\n NameOfTheCompany, \n SubjectOfAnnouncement \n DescriptionOfAnnouncement\n AttachmentURL \n DateAndTimeOfSubmission \n CategoryOfAnnouncement\n TypeOfAnnouncement\n\nImportant instructions:\n- Do the above data extraction **ONLY for the first page**\n- If there is no XBRL link, you can ignore that annoucement\n\nReturn the data as a list of dictionaries like:\n[\n  {\n    \"ScripCode\": \"\",\n    \"NameOfTheCompany\": \"\",\n    \"SubjectOfAnnouncement\": \"\",\n    \"DescriptionOfAnnouncement\": \"\",\n    \"AttachmentURL\": \"\",\n    \"DateAndTimeOfSubmission\": \"\",\n    \"CategoryOfAnnouncement\": \"\",\n    \"TypeOfAnnouncement\": \"\"\n  },\n  ..\n]\n",
    "task_id": "1568496",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Go to https://www.zolo.ca/ and select Price and write 1600000. Then find homes with 4 bedrooms then search for homes near scott road 80 ave. Then create a json file of their addresses, price, bedrooms",
    "task_id": "246025",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "visit: https://www.uniquemallorca.com/ and search for all properites in all areas",
    "task_id": "1015772",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "go to https://www.narpm.org/find/property-managers/ and for each of the property manager cards, click VIEW PROFILE then give me the phone number on that popup. then close that popup. go to the next one on the right of it. When there are no more on the right of it, go down a level and continue until the page is done. Do not paginate.",
    "task_id": "1618713",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Goal: Find specific technical information about the malicious code that was injected into GlueStack packages, particularly gluestack-ui/utils and react-native-aria.\nBackground motivation: Searching for detailed information about the GlueStack supply chain attack that affected npm packages in 2023-2024.\nExpected output format: Technical details about the attack including when it happened, what malicious code was injected, and how the attack was executed.\n\nCandidate URLs: \n- https://www.snyk.io/blog/gluestack-supply-chain-attack\n- https://thehackernews.com/search?q=gluestack\n- https://portswigger.net/daily-swig/search?q=gluestack\n- https://therecord.media/search?q=gluestack",
    "task_id": "2013081",
    "category": "Web Research"
  },
  {
    "confirmed_task": "\n    Explore the McGrath real estate website (https://www.mcgrath.com.au) and gather the following information:\n    1. Find the search input field for postcodes and its CSS selector\n    2. Find the search button and its CSS selector\n    3. Navigate to search results for postcode 2095\n    4. For property listings, identify:\n       - Container element selector\n       - Price element selector\n       - Bedrooms element selector\n       - Bathrooms element selector\n       - Car spaces element selector\n       - Property URL element selector\n    5. Identify pagination mechanism and its selector\n    6. Determine optimal wait times for each element\n    \n    Return the findings in this exact JSON format:\n    {\n        \"base_url\": \"https://www.mcgrath.com.au\",\n        \"selectors\": {\n            \"search_input\": {\"selector\": \"css_selector\", \"type\": \"css\", \"wait_time\": number},\n            \"search_button\": {\"selector\": \"css_selector\", \"type\": \"css\", \"wait_time\": number},\n            \"listing_container\": {\"selector\": \"css_selector\", \"type\": \"css\", \"wait_time\": number},\n            \"price\": {\"selector\": \"css_selector\", \"type\": \"css\", \"wait_time\": number},\n            \"bedrooms\": {\"selector\": \"css_selector\", \"type\": \"css\", \"wait_time\": number},\n            \"bathrooms\": {\"selector\": \"css_selector\", \"type\": \"css\", \"wait_time\": number},\n            \"carspaces\": {\"selector\": \"css_selector\", \"type\": \"css\", \"wait_time\": number},\n            \"listing_url\": {\"selector\": \"css_selector\", \"type\": \"css\", \"wait_time\": number}\n        },\n        \"pagination\": {\n            \"type\": \"load_more\",\n            \"selector\": \"css_selector\",\n            \"wait_time\": number\n        },\n        \"navigation\": {\n            \"search_url\": \"discovered_url_here\",\n            \"postcode_param\": \"discovered_param_here\"\n        }\n    }\n    ",
    "task_id": "1762101",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "go to amazon.com and find latest iphone 15 pro max and give me all prices of all variants with their colors and storage options and make a detailed report of it",
    "task_id": "848840",
    "category": "Price Scraping"
  },
  {
    "confirmed_task": "go to www.canon.de and get all product information for system cameras. add these to a table \n\n",
    "task_id": "1130803",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Goal: Find detailed information about the SRP authentication flow and cryptographic operations in the alexrudd/cognito-srp library\nBackground motivation: Need to understand the specific implementation details of the SRP protocol, including the authentication flow steps, cryptographic operations performed, and security aspects of the library\nExpected output format: Technical details about the SRP implementation, code examples showing the authentication flow, cryptographic calculations, and security considerations\n\nCandidate URLs: \n- https://github.com/alexrudd/cognito-srp\n- https://pkg.go.dev/github.com/alexrudd/cognito-srp",
    "task_id": "1297694",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "---\ntarget: www.zalando.de\ncatalogUrl: /damenbekleidung\n---\n\n# Search Functionality Test\n\n## Description\nTest the search functionality and its autocomplete behavior in the catalog.\n\n## User Journey\n\n### Basic Search Interaction\n1. Visit the catalog url\n   - Verify that the page has loaded successfully\n   - Check that the page has a grid of products\n\n2. Interact with search:\n   - Find the search box in the header\n   - Click to activate the search box\n   - Type \"hosen\" into the search box\n\n3. Observe search results:\n   - Autocomplete dropdown should appear\n   - Search suggestions should be visible\n\n### Keyboard Navigation in Search Results\n1. Visit the catalog page\n\n2. Start a search:\n   - Find and click the search box in the header\n   - Type \"hosen\" into the search box\n\n3. Navigate suggestions:\n   - Look at the dropdown with search suggestions\n   - Press the down arrow key twice to move through suggestions\n   - Observe the highlighted suggestion\n\n## Expected Behavior\n- The search box should be easily findable in the header\n- Typing should trigger autocomplete suggestions\n- Keyboard navigation should work in the suggestions dropdown\n- Search interface should be responsive to user input\n- No hydration mismatch issues should occur\n",
    "task_id": "1356606",
    "category": "UI Testing"
  },
  {
    "confirmed_task": "wisconsinsurplus.com visit the site and extract the auction item details including prices, current bids, next minimum bid amounts, and images",
    "task_id": "1007520",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Browser agent: Extract district heatmap of rental yields from Bayut MarketWatch at https://www.bayut.com/mybayut/dubai-property-market-report/, return in markdown format",
    "task_id": "1821571",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\n            Find the website for Uniform Commercial Code (UCC) Filings - Ohio Secretary of State or use Google to search for the All Side Roofing and Restoration LLC on Uniform Commercial Code (UCC) Filings - Ohio Secretary of State (this method works best with non goverment websites such as linkedin).\n            Search for the company 'All Side Roofing and Restoration LLC' with context: {\"location\": \"226 E 6th St, Dayton OH, 45402 USA\"} using the method: Search by company name 'All Side Roofing and Restoration LLC' to identify any UCC filings, which could indicate lenders or secured creditors..\n            Extract the following attributes: secured party, debtor, collateral.\n            Export all found information in structured JSON format.\n            You must include the URL you extracted the data from in the results.\n            Do not try to login to any website. You do not have credentials for any login.  \n            If at any point you get blocked by cloudflare, attempt to bypass it.  If you are unable to do so STOP.",
    "task_id": "1244725",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\n            Find the website for Kentucky Court of Justice or use Google to search for the Amigos Roofing & Construction on Kentucky Court of Justice (this method works best with non goverment websites such as linkedin).\n            Search for the company 'Amigos Roofing & Construction' with context: {\"location\": \"4173 Willow Ln, Lexington KY 40516\"} using the method: Search the Kentucky Court of Justice online records for civil lawsuits, liens, and judgments involving 'Amigos Roofing & Construction'..\n            Extract the following attributes: lawsuits (plaintiff or defendant), judgments, liens.\n            Export all found information in structured JSON format.\n            You must include the URL you extracted the data from in the results.\n            Do not try to login to any website. You do not have credentials for any login.  \n            If at any point you get blocked by cloudflare, attempt to bypass it.  If you are unable to do so STOP.",
    "task_id": "1251782",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "First, navigate to https://www.imf.org/en/Publications/WEO/weo-database/2024/October. Then, extract. Return relevant information about steps taken and content extracted.",
    "task_id": "1999011",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Tesla sales data and market share by region March 2025",
    "task_id": "980324",
    "category": "Web Research"
  },
  {
    "confirmed_task": "find me contact info of Osama Abdulhadi CEO of Mawsool ",
    "task_id": "23039",
    "category": "Search"
  },
  {
    "confirmed_task": "Telkom user reviews 2024-2025 site:play.google.com OR site:appstorehq.com OR site:trustpilot.com",
    "task_id": "974226",
    "category": "Search"
  },
  {
    "confirmed_task": "Read webpage https://www.digikey.com/ and follow the prompt: Go to digikey.com, search for STPS3045CW, and extract the pricing for 1, 10, 100, 1000, and 10000 units. Also, get the manufacturer part number and the availability.",
    "task_id": "2285079",
    "category": "Price Scraping"
  },
  {
    "confirmed_task": "Navigate to the SEC EDGAR database and search for Tesla (TSLA) filings. Identify the most recent significant filings such as 10-K, 10-Q, or 8-K.",
    "task_id": "1476683",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://app.uniswap.org/explore/pools and follow the prompt: Navega por la p\\u00e1gina de pools de Uniswap y busca espec\\u00edficamente el pool ETH/USDC o USDC/WETH. Extrae todos los datos relevantes incluyendo: APY, rendimiento, TVL, volumen 24h, comisiones, y cualquier otra m\\u00e9trica visible. Si hay varios pools ETH/USDC con diferentes fee tiers, captura los datos de todos. Tambi\\u00e9n captura informaci\\u00f3n de otros pools populares como ETH/USDT, WBTC/USDC para comparaci\\u00f3n.",
    "task_id": "2003613",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://karpathy.ai/ and follow the prompt: Analyze the page for keyword usage and content optimization. Identify:\n1. Primary keywords used on the page\n2. Keyword density and placement (in titles, headings, body)\n3. Content relevance to likely search queries\n4. Content length and depth\n5. Content organization for readability\n6. Any keyword stuffing or over-optimization issues\n\nAlso, check how effectively the content aligns with likely search intents for someone searching for Andrej Karpathy or related AI topics.",
    "task_id": "1681243",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Goal: Find non-UAF Chrome vulnerabilities in 2024-2025 specifically related to WebGPU, WebAssembly, File System Access API, Web Storage, Web Workers, CSS Module, Web Transport\n\nCandidate URLs: \n- https://chromereleases.googleblog.com/2024/\n- https://nvd.nist.gov/vuln/search/results?form_type=Advanced&results_type=overview&search_type=all&cpe_vendor=cpe%3A%2F%3Agoogle&cpe_product=cpe%3A%2F%3Agoogle%3Achrome",
    "task_id": "1077220",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Extract the following information as JSON from this product page:\nURL: https://www.uniqlo.com/kr/ko/products/E461011-000/00?colorDisplayCode=08&sizeDisplayCode=004\n\nRequired fields:\n- `name`: Product name\n- `skus`: List of SKUs with price, stock availability, and options\n- `images`: List of image URLs\n- `currency`: Currency code\n- `detailHtml`: Full HTML content of the product description\n- `optionGroups`: List of option groups, each containing:\n  - `name`: Option group name\n  - `options`: List of options with `name` and `imageUrl` (if available, otherwise an empty string)\n\nRespond with a well-formatted JSON structure.",
    "task_id": "221599",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "crawl and scrape all product data, including handling pagination, from https://skymint.com/white-cloud/category/flower, https://skymint.com/white-cloud/category/pre-rolls/, https://skymint.com/white-cloud/category/vaporizers/, https://skymint.com/white-cloud/category/edibles/, and https://skymint.com/white-cloud/category/concentrates/",
    "task_id": "124347",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Go to https://www.amazon.in/.\nSearch for the product: watch for men.\nScroll to load more items if needed.\nExtract the title and price of at least 20 products.\nReturn ONLY raw CSV (comma-separated values) with two columns: 'Title' and 'Price'.",
    "task_id": "1384482",
    "category": "Search Results Extracting"
  },
  {
    "confirmed_task": "\nPhase 3: Data Collection Workflow\n\nYour task is to act as an AI agent that discovers leads for a Raw Materials Importer in the Philippines.\nFollow these steps:\n\n1. Scrape Philippine Government Portals:\n   - Target the PhilGEPS website (https://www.philgeps.gov.ph).\n   - Search for public procurement tenders \n   - Extract: Company Name, Contact Details, Address, Industry, Products\n   - If information is unavailable, do a quick research with google and try to fill in as much of the missing information. Do not hallucinate information.\n\n2. Extract from Local B2B Directories:\n   - Target the Ango PH website (https://ango.ph/) and filter by categories like \"Raw Materials\" or \"Manufacturing\".\n   - Extract: Company Name, Contact Details, Address, Industry, Products\n\n3. Data Aggregation:\n   - Combine and deduplicate the extracted data.\n\n4. Report Generation:\n   - Prepare data for Google Sheets upload with fields: Company Name, Contact Details, Address, Industry, Products\n",
    "task_id": "1012772",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "site:saflii.org/za/cases 'insurance policy fraud clause' landmark judicial reasoning South Africa",
    "task_id": "794784",
    "category": "Search"
  },
  {
    "confirmed_task": "ERCOT energy imbalance service (EIS) participation rules for V2G",
    "task_id": "46438",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Goal: Gather detailed information about the identified Rails and GraphQL Ruby authentication CVEs\nExpected output: Full details for each CVE including exact vulnerability description, affected components, severity ratings, and any remediation information\n\nCandidate URLs: \n- https://nvd.nist.gov/vuln/detail/CVE-2025-27407\n- https://nvd.nist.gov/vuln/detail/CVE-2024-47887\n- https://nvd.nist.gov/vuln/detail/CVE-2021-41275\n- https://nvd.nist.gov/vuln/detail/CVE-2021-41274\n- https://nvd.nist.gov/vuln/detail/CVE-2020-8167\n- https://nvd.nist.gov/vuln/detail/CVE-2020-8166\n- https://github.com/advisories/GHSA-q92j-grw3-h492",
    "task_id": "1195938",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Navigate to: https://www.withroam.com/zipcode/91101?bedrooms=2&down_payment=400000&mode=viewport&order=ir_low&property_types=single_family&viewport=-118.47145%3A33.55095%3A-117.35938%3A34.24766\n            Meaning: Pull the Listing URL, Address, Price, Property Type, date of listing.\n            For sale in Pasadena, CA.\n            For sale in Orange County, CA.\n            ",
    "task_id": "352644",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Read webpage https://www.car.org/marketdata/data and follow the prompt: Access the California Association of Realtors (C.A.R.) market data page (https://www.car.org/marketdata/data). Look for recent reports or data sets (2023-2025) related to California housing inventory. Extract key statistics on housing supply, months of unsold inventory, or new listings vs. demand. Download relevant PDF/XLS files if available and summarize key findings.",
    "task_id": "1706786",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "recent changes in meta ads 2024 advantage+ campaigns interest free targeting",
    "task_id": "1005071",
    "category": "Search"
  },
  {
    "confirmed_task": "Read webpage https://warmembracegifts.com/ and follow the prompt: Navigate through this website to find and document all individual products with their specific details including:\n- Exact product names\n- Prices \n- Product descriptions\n- Categories (T-shirts, jewelry, candles, blankets, etc.)\n- Any special features or benefits mentioned\n\nPlease explore different product categories and pages to get a comprehensive list of all available products.",
    "task_id": "2271368",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "CONTEXT: title='About Event Security' website='https://www.boisestate.edu/publicsafety-security/event-security/about-event-security/'\nThis result item is from a search for 'event security near {METRO_AREA}'\nTASK: Determine if this is a security company website\n1. Skip if the website is clearly a directory/listing site (like Yelp, Yellow Pages, Chamber of Commerce, etc.) \n2. Skip if the website is a duplicate of a previous result saved in memory\n3. If site is potentially a security company, visit the site to confirm the site is a security company\n4. For a confirmed security company website, extract: \n   - company name \n   - company website URL (the base url, ignoring whatever page might have shown in the results) \n5. Use save_filtered_result() to save confirmed security company search results to CSV.\n6. Save the result in memory to prevent duplicates",
    "task_id": "1057833",
    "category": "Search Results Extracting"
  },
  {
    "confirmed_task": "Walmart forward outlook and recent guidance updates",
    "task_id": "769413",
    "category": "Web Research"
  },
  {
    "confirmed_task": "go to https://msrc.microsoft.com/update-guide/vulnerability, sort the list by release date, only consider those from february, that have the word the \"remote\" the \"cve title\", give me their CVE number, open their details and take note of their Metrics score ( looks like CVSS something )",
    "task_id": "500831",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Visit major consulting firms' methodology pages and extract structured data:1. McKinsey Insights: Extract frameworks like 7S, MECE, Issue Trees with detailed explanations2. BCG Insights: Get Growth-Share Matrix, Experience Curve methodologies3. Bain Insights: Extract Results Delivery Framework and case study approaches4. Deloitte Insights: Digital transformation methodologies and frameworks5. PwC Strategy: Business transformation approaches and toolsFor each framework, extract: Title, Description, When to use, Step-by-step process, Expected outcomesFormat as structured JSON with clear sections for each methodology.",
    "task_id": "649583",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "You are a None in the None department. Perform the following task:\n<task>Analyze Freshworks Product Offerings</task>\n<goals>['List all main products offered by Freshworks and their key benefits.', 'Identify integration options available for each product.', 'Prepare a comparative analysis of their customer support solutions.']</goals>\n<correctness_criteria>The analysis should accurately reflect the current product offerings and any integration partnerships mentioned on the website.</correctness_criteria>\n<websites>['www.freshworks.com']</websites>",
    "task_id": "1406368",
    "category": "Web Research"
  },
  {
    "confirmed_task": "\n        System: You are a real estate AI with this brand style: salt life outdoorsman fisher man, Professional yet approachable tone, emphasizing real estate in Southwest Florida.. Use vision to analyze images and search X for trending hashtags.\n        Search 'Southwest Florida real estate demographics' on Google, visit reliable HTML sources (e.g., census.gov), avoiding PDFs.\n        Extract demographics (age, income, trends), identify target audience.\n        Search X for trending real estate hashtags in Southwest Florida as of 2025-02-26.\n        Generate:\n        - An image prompt for a text-to-image generator.\n        - A Facebook caption with top 5 trending hashtags, styled per brand.\n        Output as JSON with 'image_prompt' and 'caption'.\n        ",
    "task_id": "846480",
    "category": "Web Research"
  },
  {
    "confirmed_task": "visit this website 'https://www.acquistinretepa.it/opencms/opencms/scheda_altri_bandi.html?idBando=51e7896e855eabe7', extract the tender information on the website and compare it with this tender {tender name: 'CUC dei Comuni dell'Area Nolana COMUNE DI CARDITO', tender description: 'CONCESSIONE DEL SERVIZIO DI RISCOSSIONE COATTIVA DI TUTTE LE ENTRATE TRIBUTARIE E PATRIMONIALI DEL COMUNE DI CARDITO, DEL RECUPERO EVASIONE DELL'IMU E TARI E DELLA GESTIONE DEL CANONE UNICO PATRIMONIALE (CUP) COMPRESO IL SERVIZIO DI GESTIONE MATERIALE DELLE PUBBLICHE AFFISSIONI DEL COMUNE DI CARDITO'.}. No need explanation and pleasantary on your response. just answer with one word as completion: \"YES\" or \"NO\". ",
    "task_id": "1504989",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "\n    Go to https://www.redfin.ca/ and enter the vancouver in the input box and then press the search button. After the page loads select price\n    and enter the 750000 underneath maximum. After that select the Beds & Bath and select 1 beds.\n    After the page loads, select all filters and scroll down until keyword search appears then add Keywords are: luxury, new build, trusted developer, quiet. to the keywords section.\n    After the page loads Extract maximum 5 properties with their addresses, prices, beds. \n\n        ",
    "task_id": "1067771",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "# Task\nYou are researching a Zapier integration issue.\nDo as much research as possible and gather as much information as possible.\n\n## Guidelines\n1. Do 2-3 different queries before arriving to your answer\n2. Final output should be the answer on how to FIX the problem\n3. You are a Zapier employee that is trying to fix our integrations\n\n## Issue\nUser is reporting an issue with their Freshdesk integration. They are trying to create a new ticket but it is saying 'subjects' does not exist.\n",
    "task_id": "1715220",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Read webpage https://www.iea.org/reports/electricity-grids-and-secure-energy-transitions/executive-summary and follow the prompt: Extract comprehensive information about global electricity grid modernization policies, investment requirements by country, and specific policy recommendations for developed and developing countries. Focus on grid infrastructure upgrades, rural electrification, and policy frameworks.",
    "task_id": "1771670",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "DeepSeek R1 70B cloud API providers",
    "task_id": "55028",
    "category": "Search"
  },
  {
    "confirmed_task": "\n        Get 100 item images from https://taobao.com. \n        You act like a human being, go straight to items, that are with an image, a title and a price.\n        You only get the title and the price for me.\n        Try not to leave the page to save time.\n        Scroll down only when you've got the information of all items on the screen.\n        Never use \"Extract_Content\" function on the website! Never search!\n        ",
    "task_id": "885584",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "cauta pe https://google.ro produsul 'Jordan 4 Retro Thunder (2023) colecteaza link-urile, intra in fiecare dintre ele si colecteaza {pret:marime:disponibilitate} pentr fiecare",
    "task_id": "381672",
    "category": "Search Results Extracting"
  },
  {
    "confirmed_task": "Execute the following steps on https://qacrmdemo.netlify.app/: Steps:\n1. Open the website.\n2. Navigate to the section dedicated to reports.\n3. Look for the 'Create New Report' button or link and click it.\n4. Fill in the required fields with appropriate test data, such as report title, description, and any necessary filters or parameters.\n5. Click the 'Submit' or 'Generate Report' button to create the report.\n6. Verify that the report generation process is initiated, possibly signaled by a loading icon or a progress bar.\n7. Once the report is generated, check for a confirmation message indicating successful creation.\n8. Locate the list or page where the new report should be displayed.\n9. Ensure the new report appears in the list, with correct title and details as entered.",
    "task_id": "891889",
    "category": "UI Testing"
  },
  {
    "confirmed_task": "Virginia DMV vehicle inspection requirements non-commercial vehicles AND alcohol delivery secure transport ID verification",
    "task_id": "91958",
    "category": "Web Research"
  },
  {
    "confirmed_task": "go on amazon india website. Search for iphones. Give me the details of the top 10 products that come.",
    "task_id": "870674",
    "category": "Search Results Extracting"
  },
  {
    "confirmed_task": "\n    Task: Collect comprehensive information from Visa's latest earnings for analyst report.\n    \n    Steps:\n    1. Go to https://www.google.com\n    2. Search for \"Visa Q4 2024 earnings results investor relations\"\n    3. Access the official IR website and locate:\n       - Latest quarterly earnings release\n       - Earnings presentation\n       - Earnings call transcript\n       - Financial supplements\n    \n    4. For each document, extract and collect:\n       - Key financial metrics:\n         * Revenue and growth\n         * Net income and margins\n         * EPS and growth\n         * Operating metrics\n         * Cash flow and balance sheet highlights\n       - Business segment performance\n       - Management commentary on:\n         * Strategic initiatives\n         * Market conditions\n         * Future outlook\n         * Key growth drivers\n    \n    5. Format the collected information as:\n       Report URLs: [url1, url2, url3]\n       \n       Financial Highlights:\n       - Revenue: $X.XX billion (+Y% YoY)\n       - Net Income: $X.XX billion\n       - EPS: $X.XX\n       [Additional metrics...]\n       \n       Business Highlights:\n       - Segment 1: [Performance details]\n       - Segment 2: [Performance details]\n       [Additional segments...]\n       \n       Management Outlook:\n       - [Key points from management commentary]\n       - [Future guidance]\n       - [Strategic initiatives]\n    \n    Important:\n    - Focus on collecting comprehensive data for analyst report\n    - Extract both quantitative and qualitative information\n    - Include YoY comparisons where available\n    - Capture management's forward-looking statements\n    - Save detailed information to analysis_results/visa_latest_reports_raw.txt\n    ",
    "task_id": "205360",
    "category": "Direct Web Scraping"
  },
  {
    "confirmed_task": "Update these model parameters and provide the reference URL for where you got the information:\n{\n  \"cohere.command-text-v14\": {\n    \"modelName\": \"Command\",\n    \"providerName\": \"Cohere\",\n    \"input_modalities\": [\n      \"TEXT\"\n    ],\n    \"output_modalities\": [\n      \"TEXT\"\n    ],\n    \"context_window\": 4096,\n    \"max_output_tokens\": 1024\n  }\n}\n\nFocus on finding the most accurate and up-to-date information about:\n1. Context window size (in tokens)\n2. Maximum output tokens\n3. Input and output modalities\n4. Streaming support\n\nFor Anthropic Claude models, check the official Anthropic documentation.\nFor Cohere models, check the official Cohere documentation.\nFor other models, check the AWS Bedrock documentation.\n\nReturn the updated parameters in valid JSON format.\n",
    "task_id": "1564425",
    "category": "Web Research"
  },
  {
    "confirmed_task": "Read webpage https://www.semrush.com/website/ and follow the prompt: Go to the Semrush website traffic analysis tool. Enter the domain 'thedefiant.io' and extract the estimated monthly traffic, top organic keywords, and a list of their main organic competitors.",
    "task_id": "2136340",
    "category": "Direct Web Scraping"
  }
]